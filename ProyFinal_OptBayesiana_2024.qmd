---
title: "Optimización Bayesiana para busqueda de hiperparámetros"
author:
  - Blanca E. García Manjarrez - ID: 118886
  - Sofia Gerard Riba - ID: 149721
  - Thomas M. Rudolf - ID: 169296
  - Yuneri Pérez Arellano - ID: 199813
format:
  pdf:
    toc: true
    toc-title: "Índice"
    toc-depth: 3
    number-sections: true
    df-print: paged
    keep-tex: true
    pdf-engine: xelatex
    tbl-colwidths: auto
    documentclass: scrartcl
fontsize: 12pt
geometry: "a4paper, margin=2.5cm"
mainfont: Arial
header-includes:
  - |
    ```{=latex}
    % Configuración de espaciado
    \usepackage{setspace}
    \doublespacing

    % Configuración de salto de página después del índice
    \usepackage{etoolbox}
    \pretocmd{\tableofcontents}{\cleardoublepage}{}{}
    
    % Paquetes necesarios para tablas y ajuste al ancho
    \usepackage{booktabs}
    \usepackage{caption}
    \captionsetup{font=small, labelfont=bf}
    \usepackage{float}
    \usepackage{adjustbox}
    \usepackage{longtable}
    \usepackage{array}
    
    % Configuración para tablas con formato numérico
    \usepackage{siunitx}
    \sisetup{
      round-mode=places,
      round-precision=3,
      group-separator={,},
      group-minimum-digits=4
    }

    % Configuración para enlaces y referencias
    \usepackage{hyperref}
    \hypersetup{
      colorlinks=true,
      linkcolor=blue,
      urlcolor=blue,
      citecolor=red
    }

    % Manejo flexible de palabras largas
    \sloppy

    % Redefinir encabezados con KOMA-Script
    \RedeclareSectionCommand[
      beforeskip=-1ex plus -1ex minus -.2ex,
      afterskip=1ex plus .2ex,
      font=\Large\bfseries\centering
    ]{section}
    \RedeclareSectionCommand[
      beforeskip=-1.5ex plus -1ex minus -.2ex,
      afterskip=0.8ex plus .2ex,
      font=\normalsize\bfseries\centering
    ]{subsection}
    \RedeclareSectionCommand[
      beforeskip=-1.5ex plus -1ex minus -.2ex,
      afterskip=0.5ex plus .2ex,
      font=\normalsize\bfseries
    ]{subsubsection}
    ```
execute:
  echo: false
  warning: false
  error: false
---


```{=latex}
\newpage
```

# Optimización Bayesiana para búsqueda de hiperparámetros

## Introducción

En el ámbito de la ciencia de datos y el aprendizaje automático, la selección de hiperparámetros es una tarea esencial para garantizar el desempeño óptimo de los modelos predictivos. Los hiperparámetros, a diferencia de los parámetros ajustados durante el entrenamiento, son configuraciones definidas previamente que afectan directamente la capacidad de generalización de los modelos, es decir, su habilidad para aprender patrones complejos y evitar problemas como el sobreajuste o el subajuste.

Técnicas como la búsqueda en cuadrícula (`GridSearch`) y la búsqueda aleatoria (`RandomSearch`) han sido ampliamente utilizadas para esta tarea. Sin embargo, ambas presentan limitaciones significativas: son computacionalmente costosas en espacios de búsqueda grandes y carecen de estrategias para priorizar configuraciones prometedoras.

La optimización bayesiana ha emergido como una solución eficiente y efectiva para abordar este tipo de desafíos. Esta técnica, combina principios probabilísticos y de optimización para modelar iterativamente el espacio de búsqueda. Al construir un modelo probabilístico del rendimiento del modelo en función de los hiperparámetros, permite identificar de manera estratégica configuraciones que optimizan métricas como la pérdida logarítmica o la precisión.

En este proyecto, exploramos la aplicación de la optimización bayesiana para la búsqueda de hiperparámetros en modelos de aprendizaje automático y profundo. A través de herramientas como procesos gaussianos (Gaussian Processes), estimadores Parzen estructurados en árbol (Tree-structured Parzen Estimators, TPE), y otras metodologías avanzadas, para evaluar su eficacia frente a enfoques tradicionales. Además, analizaremos sus beneficios, desafíos y limitaciones, proporcionando un marco claro para su implementación en proyectos prácticos.


## Búsqueda de Hiperparámetros

La importancia de un ajuste adecuado de hiperparámetros, ha sido ampliamente reconocida en la literatura científica, ya que puede mejorar significativamente el rendimiento y la generalización de los modelos. Existen diversos enfoques descritos, desde métodos manuales hasta algoritmos automáticos basados en optimización global.

```{=latex}
\newpage
```


**Limitaciones de Enfoques Tradicionales**

1. **Búsqueda en cuadrícula (*Grid Search*):**

Este enfoque realiza una búsqueda exhaustiva, evaluando todas las combinaciones posibles dentro de un rango predefinido de hiperparámetros. Aunque garantiza la exploración completa del espacio, es ineficiente en términos computacionales, especialmente en espacios de alta dimensión.

2. **Búsqueda aleatoria (*Random Search*):**

Aquí, los hiperparámetros se seleccionan aleatoriamente dentro de los límites definidos. Aunque mejora la eficiencia respecto al Grid Search, carece de una estrategia para priorizar configuraciones prometedoras, lo que resulta en un rendimiento variable en problemas complejos.

3. **Optimización Bayesiana:**

La optimización bayesiana, aborda estas limitaciones al construir un modelo probabilístico del rendimiento del modelo, en función de los hiperparámetros. Este enfoque, guía la búsqueda hacia configuraciones óptimas mediante un equilibrio entre **exploración** (*probar regiones poco exploradas*) y **explotación** (*ajustar configuraciones prometedoras*).

![Comparativo de enfoques para búsqueda de hiperpárametros](imgs/Comparacion_Search.png)

**Estudios destacados incluyen:**

- En [1], se demostró que la optimización bayesiana, aplicada a modelos como bosques aleatorios y redes neuronales profundas (CNN, RNN), supera en eficiencia y precisión a los enfoques tradicionales.
- En [2], se destacó la capacidad del estimador TPE para ajustar hasta 32 hiperparámetros en modelos complejos como redes de creencias profundas (DBN).
- En [3], se validó la superioridad de la optimización bayesiana en términos de velocidad y rendimiento, especialmente en espacios de búsqueda de alta dimensión o recursos computacionales limitados.

## Optimización de Hiperparámetros

El ajuste de hiperparámetros puede entenderse como un problema de optimización de funciones de caja negra (*BlackBox*), donde la función objetivo (por ejemplo, la métrica de evaluación del modelo) no tiene una expresión cerrada, ni derivadas accesibles. Esto dificulta el uso de métodos tradicionales como el descenso de gradiente.

### Enfoques Automáticos

1. **Grid Search**:

Proporciona un marco exhaustivo, pero enfrenta la maldición de la dimensionalidad, limitando su aplicabilidad en problemas complejos.

2. **Random Search**:

Aunque más eficiente, carece de una estrategia para explotar información previa o configuraciones prometedoras.

### Ventajas de la Optimización Bayesiana

Integra información previa sobre el espacio de búsqueda, para actualizar la distribución posterior iterativamente.
Utiliza funciones de adquisición, para decidir las siguientes configuraciones a probar, optimizando recursos computacionales.Es decir, modela el rendimiento del modelo de manera probabilística, permitiendo una exploración más eficiente y efectiva del espacio de hiperparámetros.

![Esquema de enfoques en la búsqueda de hiperpárametros](imgs/esquema_enfoques_HPO.png)

## Fundamentos Matemáticos de la Optimización Bayesiana

La optimización bayesiana busca maximizar una función objetivo $f(x)$ desconocida en un espacio de búsqueda $A$, utilizando el siguiente enfoque:

$$
x^+ = \underset{x \in A}{\text{arg max }} f(x) : \tag{1}
$$

Se basa en el [teorema de Bayes](https://arxiv.org/pdf/1012.2599.pdf), el cual establece que, dado un conjunto de datos evidenciales $E$, la probabilidad posterior $P(M|E)$ de un modelo $M$, es proporcional a la probabilidad $P(E|M)$, de observar $E$, dado el modelo $M$, multiplicada por la probabilidad previa $P(M)$:

$$
P(M|E) \propto P(E|M)P(M) : \tag{2}
$$


La fórmula anterior, refleja la idea central de la optimización bayesiana. El principio consiste en combinar la distribución previa de la función $f(x)$ con la información de las muestras (evidencia) para obtener la distribución posterior de la función. Luego, se utiliza esta información posterior para determinar dónde se maximiza la función $f(x)$ según un criterio. En otras palabras,combina una distribución previa, con evidencia obtenida durante la búsqueda, para actualizar la distribución posterior de $f(x)$.

El criterio se representa mediante una función de utilidad $u$, también llamada **función de adquisición**. La función $u$ se utiliza para determinar el siguiente punto de muestreo, con el fin de maximizar la utilidad esperada. Al explorar el área de muestreo, es necesario considerar tanto la exploración (muestreo en áreas de alta incertidumbre), como la explotación (muestreo en áreas con valores altos). Este equilibrio ayuda a reducir el número de muestras necesarias y mejora el rendimiento, incluso cuando la función tiene múltiples máximos locales.

### Proceso Gaussiano (GP)

Es una técnica, basada en la teoría de probabilidad gaussiana y aprendizaje bayesiano. A diferencia de una distribución gaussiana, que describe variables escalares o vectores, un proceso gaussiano describe **propiedades de funciones**. Específicamente, un proceso gaussiano, asume que cualquier subconjunto finito de valores aleatorios sigue una distribución gaussiana multivariada. 

Un GP se define por su función media $m(x)$ y su función de covarianza $k(x, x')$, representado como:

$$
f(x) \sim GP(m(x), k(x, x'))
$$
```{=latex}
\newpage
```


- **Función de Covarianza**

Una función común para $k(x_i, x_j)$, es la exponencial cuadrada:

$$
k(x_i, x_j) = \exp\left(-\frac{1}{2} \|x_i - x_j\|^2\right)
$$
donde $x_i$ y $x_j$ son puntos de muestreo. Si $x_i$ y $x_j$ están cerca, $k(x_i, x_j)$ se aproxima a 1; de lo contrario, tiende a 0. Esto representa la correlación y la influencia mutua entre los puntos.

- **Predicción y Varianza:**

Se calcula la media $\mu_{t+1}(x_{t+1})$ y varianza $\sigma^2_{t+1}(x_{t+1})$ para determinar el siguiente punto a evaluar.

![Fuente (3) Proceso Gaussiano](imgs/Proceso_Gaussiano_1Dim.png)


### Función de Adquisición

La función de adquisición o función de utilidad $u(x)$, determina el próximo punto a muestrear, equilibrando exploración y explotación con el fin de maximizar la utilidad esperada.
Al explorar el área de muestreo, es necesario considerar tanto la exploración (muestreo en áreas de alta incertidumbre), como la explotación (muestreo en áreas con valores altos). Este equilibrio ayuda a reducir el número de muestras necesarias y mejora el rendimiento, incluso cuando la función tiene múltiples máximos locales.
Ejemplos:

```{=latex}
\newpage
```

1. **Probabilidad de Mejora (PI)**

La función PI, busca puntos donde el valor de $f(x)$ sea mayor al valor óptimo actual $f(x^+)$. La probabilidad de mejora se expresa como:
$$
PI(x) = P(f(x) \geq f(x^+)) = \Phi\left(\frac{\mu(x) - f(x^+)}{\sigma(x)}\right),
$$
donde 

$\Phi(\cdot)$ es la función de distribución acumulativa de la normal estándar. 

Una versión extendida de PI introduce un parámetro $\epsilon$ para garantizar que el nuevo punto muestreado supere al óptimo actual por al menos $\epsilon$:
$$
PI(x) = \Phi\left(\frac{\mu(x) - f(x^+) - \epsilon}{\sigma(x)}\right).
$$

2. **Mejora Esperada (EI)**

La función *EI*, calcula la expectativa del grado de mejora que puede lograrse al explorar un punto cerca del óptimo actual. La mejora esperada se define como:
$$
E(x) = \max\{0, f_{t+1}(x) - f(x^+)\}.
$$
Maximizamos la *EI* respecto al valor óptimo actual $f(x^+)$:
$$
x = \underset{x}{\text{arg max }} E[I(x)].
$$
La expresión para *EI* es:
$$
E(I) = \sigma(x) \left[ Z \Phi(Z) + \phi(Z) \right],
$$
donde 

$Z = \frac{\mu(x) - f(x^+)}{\sigma(x)}$, $\Phi(\cdot)$ es la función acumulativa y 

$\phi(\cdot)$ es la densidad de probabilidad de la normal estándar.


3. **Límite Superior de Confianza (GP-UCB)**

La función GP-UCB, decide si el próximo punto a muestrear debe explotar el valor óptimo actual (zona de alta $\mu(x)$) o explorar zonas de alta incertidumbre $(\sigma(x))$. El equilibrio se controla mediante el parámetro $\kappa$:
$$
UCB(x) = \mu(x) + \kappa \sigma(x).
$$

En la siguiente imagen se compara el rendimiento de las funciones PI, EI y GP-UCB en el proceso de optimización. Las líneas azules representan la media posterior, mientras que las áreas sombreadas muestran la incertidumbre ($\pm \sigma(x)$). EI y GP-UCB logran encontrar el valor global óptimo, mientras que PI tiende a quedarse atrapada en óptimos locales debido a su naturaleza codiciosa.

![Fuente (3) Comparación de funciones de adquisición) ](imgs/image.png)

Según los resultados experimentales, la función EI es ideal para optimizar hiperparámetros por su simplicidad y rendimiento superior en comparación con PI y GP-UCB. Sin embargo, la elección de la función de adquisición depende del problema y la función objetivo, por lo que es recomendable probar varias funciones para determinar la más adecuada.

## Implementación con NumPy y SciPy

En esta sección, implementaremos la función de adquisición y su optimización en NumPy y SciPy, así mismo usaremos scikit-learn para la el proceso gaussiano. Aunque tenemos una expresión analítica del objetivo de optimización `f` en el siguiente ejemplo, lo tratamos como una `Black-Box` y lo aproximamos iterativamente con un proceso gaussiano durante la optimización bayesiana. Además, las muestras extraídas de la función objetivo son ruidosas y el nivel de ruido está dado por la variable `noise`. La optimización se realiza dentro de los `límites` dados. También asumimos que existen dos muestras iniciales en `X_init` e `Y_init`.

Función:
$$
f(X)=-\sin(3X)-X^2+0.7X + \text{noise}*\text{randn}
$$
```{python, echo=FALSE}
import numpy as np
import matplotlib.pyplot as plt

#%matplotlib inline
np.random.seed(42)
bounds = np.array([[-1.0, 2.0]])
noise = 0.2

def f(X, noise=noise):
    return -np.sin(3*X) - X**2 + 0.7*X + noise * np.random.randn(*X.shape)

X_init = np.array([[-0.9], [1.1]])
Y_init = f(X_init)
```

La siguiente gráfica muestra:
- La función objetivo libre de ruido
- La cantidad de ruido al representar gráficamente una gran cantidad de muestras y
- Las dos muestras iniciales

```{python, echo=FALSE, mesaage=FALSE, warning=FALSE}
# Dense grid of points within bounds
np.random.seed(42)
X = np.linspace(bounds[0, 0], bounds[0, 1], 300).reshape(-1, 1)

# Noise-free objective function values at X 
Y = f(X, 0)

# Plot optimization objective with noise level 
plt.plot(X, Y, 'y--', lw=2, label='Noise-free objective')
plt.plot(X, f(X), 'bx', lw=1, alpha=0.1, label='Noisy samples')
plt.plot(X_init, Y_init, 'kx', markeredgewidth=3, label='Initial samples')
plt.legend()
plt.show()
```

El objetivo, **es encontrar el óptimo global a la izquierda**, en una pequeña cantidad de pasos. El siguiente paso es implementar la función de adquisición definida como función EI (`expected_improvement`).

```{python, echo=FALSE}
def expected_improvement(X, X_sample, Y_sample, gpr, xi=0.01):
    """
    Calcula la mejora esperada (Expected Improvement, EI) en los puntos X
    utilizando muestras X_sample, Y_sample y un modelo sustituto (Gaussian Process Regressor).

    Args:
        X (np.ndarray): Puntos donde calcular la EI (m x d).
        X_sample (np.ndarray): Ubicaciones de las muestras (n x d).
        Y_sample (np.ndarray): Valores de las muestras (n x 1).
        gpr (GaussianProcessRegressor): Modelo GP ajustado a las muestras.
        xi (float): Parámetro de exploración-explotación (default=0.01).

    Returns:
        np.ndarray: Valores de la función de adquisición EI en los puntos X.
    """
    # Predicción del modelo sustituto
    mu, sigma = gpr.predict(X, return_std=True)
    mu_sample = gpr.predict(X_sample)

    # Asegúrate de que sigma sea unidimensional
    sigma = sigma.flatten()

    # Valor máximo de la función objetivo conocido hasta ahora
    mu_sample_opt = np.max(mu_sample)

    # Calcula la EI
    with np.errstate(divide='warn'):
        imp = mu - mu_sample_opt - xi
        Z = np.divide(imp, sigma, where=(sigma != 0))  # Evita divisiones por cero
        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)

    # Establece EI a 0 donde sigma es 0
    ei[sigma == 0] = 0.0

    return ei
```

También necesitamos una función que proponga el siguiente punto de muestreo, calculando la ubicación del máximo de la función de adquisición. La optimización se reinicia `n_restarts` veces para evitar óptimos locales.

```{python, echo=FALSE}
def propose_location(acquisition, X_sample, Y_sample, gpr, bounds, n_restarts=25):
    """
    Propone el siguiente punto de muestreo optimizando la función de adquisición.

    Args:
        acquisition: Función de adquisición.
        X_sample: Ubicaciones de las muestras (n x d).
        Y_sample: Valores de las muestras (n x 1).
        gpr: GaussianProcessRegressor ajustado a las muestras.
        bounds: Límites del espacio de búsqueda (d x 2).
        n_restarts: Número de reinicios aleatorios para optimización global.

    Returns:
        np.ndarray: Ubicación del máximo de la función de adquisición.
    """
    dim = X_sample.shape[1]
    min_val = 1
    min_x = None

    def min_obj(X):
        # El objetivo de minimización es la función de adquisición negativa
        return -acquisition(X.reshape(-1, dim), X_sample, Y_sample, gpr).flatten()

    # Encuentra el mejor óptimo comenzando desde puntos aleatorios diferentes
    for x0 in np.random.uniform(bounds[:, 0], bounds[:, 1], size=(n_restarts, dim)):
        res = minimize(min_obj, x0=x0, bounds=bounds, method='L-BFGS-B')
        if res.fun < min_val:  # Aquí corregimos la comparación sin indexar res.fun
            min_val = res.fun
            min_x = res.x

    if min_x is None:
        raise ValueError("No se encontró un óptimo válido en propose_location.")

    return min_x.reshape(-1, 1)
```

Ahora tenemos todos los componentes necesarios para ejecutar la optimización bayesiana con el algoritmo descrito anteriormente. El proceso gaussiano del siguiente ejemplo está configurado con un [Matérn kernel](http://scikit-learn.org/stable/modules/gaussian_process.html#matern-kernel). El nivel de ruido conocido se configura con el parámetro `alpha`.

La optimización bayesiana, se ejecuta durante 10 iteraciones. En cada iteración, produce una fila con dos gráficos. 

- El gráfico de la izquierda muestra la función objetivo sin ruido, **la función sustituta**, que es la media predictiva posterior de Gaussian Process, el intervalo de confianza  es de 95% de la media y las muestras ruidosas obtenidas de la función objetivo hasta el momento. 
- El gráfico de la derecha muestra la función de adquisición. 
- La línea discontinua vertical en ambos gráficos muestra el punto de muestreo propuesto para la siguiente iteración, que corresponde al máximo de la función de adquisición.

```{python, echo=FALSE}
from scipy.optimize import minimize
from scipy.stats import norm

# Proceso gaussiano con kernel Matérn como modelo sustituto
np.random.seed(42)
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import ConstantKernel, Matern
from bayesian_optimization_util import plot_approximation, plot_acquisition

# Gaussian process with Matérn kernel as surrogate model
m52 = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5)
gpr = GaussianProcessRegressor(kernel=m52, alpha=noise**2)

# Initialize samples
X_sample = X_init
Y_sample = Y_init

# Number of iterations
n_iter = 10

plt.figure(figsize=(12, n_iter * 3))
plt.subplots_adjust(hspace=0.4)

for i in range(n_iter):
    # Update Gaussian process with existing samples
    gpr.fit(X_sample, Y_sample)

    # Obtain next sampling point from the acquisition function (expected_improvement)
    X_next = propose_location(expected_improvement, X_sample, Y_sample, gpr, bounds)
    
    # Obtain next noisy sample from the objective function
    Y_next = f(X_next, noise)
    
    # Plot samples, surrogate function, noise-free objective and next sampling location
    plt.subplot(n_iter, 2, 2 * i + 1)
    plot_approximation(gpr, X, Y, X_sample, Y_sample, X_next, show_legend=i==0)
    plt.title(f'Iteration {i+1}')

    plt.subplot(n_iter, 2, 2 * i + 2)
    plot_acquisition(X, expected_improvement(X, X_sample, Y_sample, gpr), X_next, show_legend=i==0)
    
    # Add sample to previous samples
    X_sample = np.vstack((X_sample, X_next))
    Y_sample = np.vstack((Y_sample, Y_next))
```
Se puede observar, cómo las dos muestras iniciales dirigen la búsqueda hacia la dirección del máximo local en el lado derecho, pero la exploración, permite que el algoritmo escape de ese óptimo local y encuentre el óptimo global en el lado izquierdo. 

Así mismo se observa también cómo las propuestas de puntos de muestreo, a menudo caen dentro de regiones de alta incertidumbre (exploración) y no solo están impulsadas por los valores más altos de la función sustituta (explotación).

Un gráfico de convergencia revela cuántas iteraciones se necesitan para encontrar un máximo y si las propuestas de puntos de muestreo se mantienen alrededor de ese máximo, es decir, convergen a pequeñas diferencias entre pasos consecutivos.

```{python, echo=FALSE}
from bayesian_optimization_util import plot_convergence
plot_convergence(X_sample, Y_sample)
```

## Librerias para la Optimización Bayesiana

Existen numerosas librerias de optimización bayesiana y el objetivo de este análisis no es brindar una descripción general de estas, sino, de ejemplificar dos y mostrar la configuración mínima necesaria para ejecutar el ejemplo anterior.

### Scikit-Optimize

[Scikit-optimize](https://scikit-optimize.github.io/) es una biblioteca para la optimización basada en modelos secuenciales que se basa en [NumPy](https://numpy.org/), [SciPy](https://scipy.org/) y [Scikit-Learn](http://scikit-learn.org/). También admite la optimización bayesiana mediante procesos gaussianos. La API está diseñada entorno a la minimización, por lo tanto, tenemos que proporcionar valores de función objetivo negativos. Los resultados obtenidos aquí difieren ligeramente de los resultados anteriores debido al comportamiento de optimización no determinista y a las diferentes muestras ruidosas extraídas de la función objetivo.

```{python, echo=FALSE}
from sklearn.base import clone
from skopt import gp_minimize
from skopt.learning import GaussianProcessRegressor
from skopt.learning.gaussian_process.kernels import ConstantKernel, Matern
from skopt.space import Real

# Define bounds as Real to avoid warnings
bounds = [Real(-1.0, 2.0)]

# Use custom kernel and estimator to match previous example
np.random.seed(42)
m52 = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5)
gpr = GaussianProcessRegressor(kernel=m52, alpha=noise**2)

# Perform Bayesian optimization
r = gp_minimize(lambda x: -f(np.array(x))[0], 
                bounds,               # Define bounds explicitly
                base_estimator=gpr,   # Use custom GP estimator
                acq_func='EI',        # Expected improvement
                xi=0.01,              # Exploitation-exploration trade-off
                n_calls=10,           # Number of iterations
                n_random_starts=0,    # Initial samples are provided
                x0=X_init.tolist(),   # Initial samples
                y0=-Y_init.ravel())   # Initial values

# Fit GP model to samples for plotting results
gpr.fit(r.x_iters, -r.func_vals)

# Plot the fitted model and the noisy samples
plot_approximation(gpr, X, Y, r.x_iters, -r.func_vals, show_legend=True)
```

```{python, echo=FALSE}
plot_convergence(np.array(r.x_iters), -r.func_vals)
```

### GPyOpt

[GPyOpt](http://sheffieldml.github.io/GPyOpt/) es una biblioteca de optimización bayesiana basada en [GPy](https://sheffieldml.github.io/GPy/). El nivel de abstracción de la API, es comparable al de scikit-optimize. 
La API `BayesianOptimization` proporciona un parámetro `maximize` para configurar si la función objetivo se maximizará o minimizará (predeterminado). En la versión 1.2.1, esto parece ignorarse al proporcionar muestras iniciales, por lo que tenemos que negar sus valores objetivo manualmente en el siguiente ejemplo. Además, los métodos integrados `plot_acquisition` y `plot_convergence` muestran el resultado de la minimización en cualquier caso. Nuevamente, los resultados obtenidos aquí difieren ligeramente de los resultados anteriores debido al comportamiento de optimización no determinista y a las diferentes muestras ruidosas extraídas de la función objetivo.

```{python}
import numpy as np
import matplotlib.pyplot as plt
import GPy
from GPyOpt.methods import BayesianOptimization

# Configuración inicial
np.random.seed(42)
bounds = np.array([[-1.0, 2.0]])
noise = 0.2

def f(X, noise=noise):
    return -np.sin(3*X) - X**2 + 0.7*X + noise * np.random.randn(*X.shape)

X_init = np.array([[-0.9], [1.1]])
Y_init = f(X_init)

# Configuración del kernel y optimización bayesiana
kernel = GPy.kern.Matern52(input_dim=1, variance=1.0, lengthscale=1.0)
#bds = [{'name': 'X', 'type': 'continuous', 'domain': bounds.flatten().tolist()}]
bds = [{'name': 'X', 'type': 'continuous', 'domain': bounds.ravel()}]

optimizer = BayesianOptimization(f=f, 
                                 domain=bds,
                                 model_type='GP',
                                 kernel=kernel,
                                 acquisition_type ='EI',
                                 acquisition_jitter = 0.01,
                                 X=X_init,
                                 Y=-Y_init,
                                 noise_var = noise**2,
                                 exact_feval=False,
                                 normalize_Y=False,
                                 maximize=True)

# Ejecutar optimización
optimizer.run_optimization(max_iter=10)
optimizer.plot_acquisition()
```

```{python, echo=FALSE}
optimizer.plot_convergence()
```


## Aplicación de Optimización Bayesiana en Aprendizaje Automático

### Diabetes

En esta sección, aplicaremos la optimización bayesiana a un problema de regresión. La regresión se realiza en un pequeño [conjunto de datos sobre diabetes](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes) que es parte de scikit-learn.

El conjunto de datos, contiene 10 variables basales como son: edad, sexo, índice de masa corporal, presión arterial media y 6 mediciones de suero sanguíneo para cada uno de los 442 pacientes diabéticos, así como la respuesta del paciente, una medida cuantitativa de la progresión de la enfermedad, un año después de la toma inicial.

|Atributo|Descripción|
|--------|-----------|
|age |age in years|
|sex| sex|
|bmi| body mass index|
|bp| average blood pressure|
|s1 tc| total serum cholesterol|
|s2 ldl| low-density lipoproteins|
|s3 hdl| high-density lipoproteins|
|s4 tch| total cholesterol / HDL|
|s5 ltg| possibly log of serum triglycerides level|
|s6 glu| blood sugar level|
| y| quantitative measure of disease progression one year after baseline|

![Estudio de diabetes](imgs/data_diabetes.png)
Fuente [Diabetes Study](https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)


**Definición del problema**

El objetivo es predecir la progresión de la enfermedad un año después del estudio, basándose en múltiples características explicativas proporcionadas en el conjunto de datos, utilizando un `XGBRegressor` con optimización bayesiana para la búsqueda de hiperparámetros.
En esta sección demostraremos cómo optimizar los hiperparámetros de un `XGBRegressor` con GPyOpt y skopt y cómo se compara el rendimiento de la optimización bayesiana (`BayesianOptimization`) con la búsqueda aleatoria (`RandomSearch`).

Matemáticamente, esto se modela como:

$$
Y = f(X; \Theta) + \epsilon
$$

Donde:

- $Y \in \mathbb{R}$ representa la variable objetivo (medida de progreso de la enfermedad).

- $X \in \mathbb{R}^{n \times d}$ es la matriz de entrada con $n$ muestras y $d$ características.

- $\Theta$ representa los hiperparámetros del modelo que afectan su capacidad de generalización.

- $\epsilon$ es un término de error (ruido) que modela incertidumbre o variabilidad no explicada por $f(X; \Theta)$.

El modelo objetivo $f(X; \Theta)$ es un `XGBRegressor` (modelo de boosting basado en árboles) que tiene múltiples hiperparámetros a optimizar.

**Función objetivo para la optimización**

El problema de ajuste de hiperparámetros se puede expresar como un problema de minimización, donde se busca el conjunto de hiperparámetros $\Theta^*$ que minimice el error cuadrático medio (MSE) en validación cruzada:

$$
\Theta^* = \underset{\Theta}{\text{argmin}} \, \frac{1}{k} \sum_{i=1}^{k} \left( \frac{1}{n_i} \sum_{j=1}^{n_i} \left( y_{ij} - \hat{y}_{ij}(\Theta) \right)^2 \right)
$$

Donde:

- $k$ es el número de pliegues en la validación cruzada.

- $n_i$ es el número de muestras en el pliegue $i$.

- $y_{ij}$ es el valor real de la muestra $j$ en el pliegue $i$.

- $\hat{y}_{ij}(\Theta)$ es la predicción realizada por el modelo con hiperparámetros $\Theta$.


**Hiperparámetros optimizados**

Los hiperparámetros ajustados ($\Theta$) incluyen:

|Hiperparámetro|Descripción|Rango|
|--------------|-----------|-----|
|Tasa de aprendizaje ($\eta$)|Controla la contribución de cada árbol en el modelo final.|$[0, 1]$|
|--------------|-----------|-----|
|Profundidad máxima de los árboles ($d$)|Controla la complejidad de los árboles.|$[1, 50]$|
|--------------|-----------|-----|
|Número de estimadores ($n_{\text{trees}}$)|Número total de árboles en el modelo.|$[1, 300]$|
|--------------|-----------|-----|
|Peso mínimo de las hojas ($w_{\text{min}}$)|Peso mínimo requerido para dividir un nodo.|$[1, 10]$|
|--------------|-----------|-----|
|Parámetro $\gamma$|Penalización por complejidad en la división de nodos.|$[0, 5]$|
|--------------|-----------|-----|

El espacio de búsqueda para los hiperparámetros es definido explícitamente en la optimización bayesiana.

**Enfoque de optimización**

Se utiliza la optimización bayesiana para encontrar $\Theta^*$. Este enfoque construye un modelo probabilístico (Proceso Gaussiano) para aproximar la relación entre los hiperparámetros $\Theta$ y la función objetivo (MSE). La técnica, guía la búsqueda hacia regiones prometedoras del espacio de hiperparámetros.

1. **Modelo probabilístico**:

   El modelo probabilístico del MSE se denota como:
   $$
   f(\Theta) \sim \mathcal{GP}(\mu(\Theta), k(\Theta, \Theta'))
   $$
   
   Donde:
   
   - $\mu(\Theta)$: Media predictiva del MSE.
   
   - $k(\Theta, \Theta')$: Función de covarianza que mide la similitud entre puntos $\Theta$ y $\Theta'$.

2. **Función de adquisición**:

   La función de adquisición (Expected Improvement, EI) guía la selección del próximo conjunto de hiperparámetros a evaluar:
   
   $$
   \text{EI}(\Theta) = \mathbb{E}\left[ \max(0, f(\Theta^*) - f(\Theta)) \right]
   $$
   
   Donde:
   
   - $f(\Theta^*)$ es el mejor valor conocido de la función objetivo.
   
   - $f(\Theta)$ es el valor predicho por el modelo probabilístico.

3. **Actualización iterativa**:

   En cada iteración:
   - Se evalúa $\text{EI}(\Theta)$ en el espacio de búsqueda.
   
   - Se selecciona el conjunto de hiperparámetros $\Theta_{\text{next}}$ que maximiza $\text{EI}(\Theta)$.
   
   - Se entrena el modelo con $\Theta_{\text{next}}$ y se actualiza el modelo probabilístico.


```{python, echo=FALSE}
import numpy as np
from sklearn import datasets
from sklearn.model_selection import RandomizedSearchCV, cross_val_score
from scipy.stats import uniform
from xgboost import XGBRegressor

np.random.seed(0)
# Load the diabetes dataset (for regression)
X, Y = datasets.load_diabetes(return_X_y=True)

# Instantiate an XGBRegressor with default hyperparameter settings
xgb = XGBRegressor()

# and compute a baseline to beat with hyperparameter optimization 
baseline = cross_val_score(xgb, X, Y, scoring='neg_mean_squared_error').mean()
```

#### Ajuste de hiperparámetros con búsqueda aleatoria

Para el ajuste de hiperparámetros con búsqueda aleatoria, utilizamos `RandomSearchCV` de scikit-learn y calculamos una puntuación de validación cruzada para cada punto seleccionado aleatoriamente en el espacio de hiperparámetros.

```{python, echo=FALSE}
import numpy as np
np.random.seed(0)
# Hyperparameters to tune and their ranges
param_dist = {"learning_rate": uniform(0, 1),
              "gamma": uniform(0, 5),
              "max_depth": range(1,50),
              "n_estimators": range(1,300),
              "min_child_weight": range(1,10)}

rs = RandomizedSearchCV(xgb, param_distributions=param_dist, 
                        scoring='neg_mean_squared_error', n_iter=25)

# Run random search for 25 iterations
rs.fit(X, Y);
```

#### Ajuste de hiperparámetros con optimización bayesiana

Para ajustar los hiperparámetros con optimización bayesiana, implementamos una función objetivo `cv_score` que toma los hiperparámetros como entrada y devuelve una puntuación de validación cruzada. Aquí, asumimos que la validación cruzada en un punto determinado en el espacio de hiperparámetros es determinista y, por lo tanto, establecemos el parámetro `exact_feval` de `BayesianOptimization` en `True`. Dependiendo del ajuste del modelo y los detalles de la validación cruzada, esto podría no ser el caso, pero lo ignoraremos aquí.

```{python, echo=FALSE}
import numpy as np
from GPyOpt.methods import BayesianOptimization

np.random.seed(0)
bds = [{'name': 'learning_rate', 'type': 'continuous', 'domain': (0, 1)},
        {'name': 'gamma', 'type': 'continuous', 'domain': (0, 5)},
        {'name': 'max_depth', 'type': 'discrete', 'domain': (1, 50)},
        {'name': 'n_estimators', 'type': 'discrete', 'domain': (1, 300)},
        {'name': 'min_child_weight', 'type': 'discrete', 'domain': (1, 10)}]

# Optimization objective 
def cv_score(parameters):
    parameters = parameters[0]
    score = cross_val_score(
                XGBRegressor(learning_rate=parameters[0],
                              gamma=int(parameters[1]),
                              max_depth=int(parameters[2]),
                              n_estimators=int(parameters[3]),
                              min_child_weight = parameters[4]), 
                X, Y, scoring='neg_mean_squared_error').mean()
    score = np.array(score)
    return score

optimizer = BayesianOptimization(f=cv_score, 
                                 domain=bds,
                                 model_type='GP',
                                 acquisition_type ='EI',
                                 acquisition_jitter = 0.05,
                                 exact_feval=True, 
                                 maximize=True)

# Only 20 iterations because we have 5 initial random points
optimizer.run_optimization(max_iter=20)
```

```{python, echo=FALSE}
import numpy as np
import pandas as pd
from skopt import gp_minimize
from skopt.space import Real, Integer
from skopt.utils import use_named_args
from sklearn.model_selection import cross_val_score
from xgboost import XGBRegressor

np.random.seed(0)
# Define los dominios de búsqueda (bounds)
search_space = [
    Real(0, 1, name='learning_rate'),               # learning_rate
    Real(0, 5, name='gamma'),                       # gamma
    Integer(1, 50, name='max_depth'),               # max_depth
    Integer(1, 300, name='n_estimators'),           # n_estimators
    Integer(1, 10, name='min_child_weight')         # min_child_weight
]

# Función objetivo para minimizar (se negará el MSE para que sea una minimización)
@use_named_args(search_space)
def cv_score(learning_rate, gamma, max_depth, n_estimators, min_child_weight):
    model = XGBRegressor(
        learning_rate=learning_rate,
        gamma=gamma,
        max_depth=max_depth,
        n_estimators=n_estimators,
        min_child_weight=min_child_weight
    )
    score = cross_val_score(model, X, Y, scoring='neg_mean_squared_error').mean()
    return -score  # Negamos el puntaje para minimizar

# Ejecutar la optimización bayesiana
result = gp_minimize(
    func=cv_score,                 # Función objetivo
    dimensions=search_space,       # Espacio de búsqueda
    acq_func='EI',                 # Expected Improvement
    n_calls=20,                    # Número de iteraciones
    n_initial_points=5,            # Puntos iniciales aleatorios
    random_state=0                # Reproducibilidad
)

# Resultados de la optimización
best_parameters = {dim.name: val for dim, val in zip(search_space, result.x)}
best_parameters['Best Negative MSE'] = result.fun
df_results = pd.DataFrame([best_parameters])
df_results = df_results.rename(columns={
    'learning_rate': 'Learning Rate',
    'gamma': 'Gamma',
    'max_depth': 'Max Depth',
    'n_estimators': 'N Estimators',
    'min_child_weight': 'Min Child Weight',
    'Best Negative MSE': 'Best Neg. MSE'
})
df_results_t = df_results.T.reset_index()
df_results_t.columns = ['Hyperparameter', 'Value']
df_results_t.reset_index(drop=True)
df_results_t
```

#### Resultados

En promedio, la optimización bayesiana encuentra un óptimo mejor en una menor cantidad de pasos que la búsqueda aleatoria y supera la línea base en casi todas las ejecuciones. Esta tendencia se vuelve aún más prominente en espacios de búsqueda de dimensiones superiores. Aquí, el espacio de búsqueda es de cinco dimensiones, lo cual es bastante bajo para obtener un beneficio sustancial de la optimización bayesiana. Una ventaja de la búsqueda aleatoria es que es fácil de paralelizar. La paralelización de la optimización bayesiana es mucho más difícil y está sujeta a investigación.

A continuación, se muestra un gráfico que compara la convergencia de la búsqueda aleatoria y la optimización bayesiana utilizando dos librerías (GPyOpt y skopt). La optimización bayesiana converge más rápidamente a un óptimo que la búsqueda aleatoria.


```{python, echo=FALSE}
# Máximos acumulados para Random Search
# Asegúrate de que 'mean_test_score' esté disponible en tu búsqueda aleatoria
if 'mean_test_score' in rs.cv_results_:
    y_rs = np.maximum.accumulate(rs.cv_results_['mean_test_score'])
else:
    y_rs = None

# Máximos acumulados para la optimización bayesiana
y_bo = np.maximum.accumulate(-np.array(result.func_vals))
baseline = -np.mean(cross_val_score(XGBRegressor(), X, Y, scoring = 'neg_mean_squared_error'))

# Graficar los resultados
plt.figure(figsize=(6, 4))
if y_rs is not None:
    plt.plot(y_rs, 'ro-', label='Random search')
plt.plot(y_bo, 'bo-', label='Bayesian optimization skopt')
plt.xlabel('Iteration')
plt.ylabel('Neg. MSE')
plt.ylim(-5000, -3000)  # Ajusta estos límites según tu problema
plt.title('Value of the Best Sampled CV Score')
plt.legend()
plt.show()
```

```{python}
y_rs = np.maximum.accumulate(rs.cv_results_['mean_test_score'])
y_bo = np.maximum.accumulate(-optimizer.Y).ravel()

plt.figure(figsize=(6, 4))
plt.plot(y_rs, 'ro-', label='Random search')
plt.plot(y_bo, 'bo-', label='Bayesian optimization GPyOpt')
plt.xlabel('Iteration')
plt.ylabel('Neg. MSE')
plt.ylim(-5000, -3000)
plt.title('Value of the best sampled CV score');
plt.legend();
```


```{python, echo=FALSE}
# Máximos acumulados para Random Search
if 'mean_test_score' in rs.cv_results_:
    y_rs = np.maximum.accumulate(rs.cv_results_['mean_test_score'])
else:
    y_rs = None

# Máximos acumulados para las optimizaciones bayesianas
y_bo_skopt = np.maximum.accumulate(-np.array(result.func_vals))
y_bo_gpyopt = np.maximum.accumulate(-optimizer.Y).ravel()

# Resultado del baseline
baseline = -np.mean(cross_val_score(XGBRegressor(), X, Y, scoring='neg_mean_squared_error'))

# Crear diccionario con todos los resultados
best_results = {
    "Method": [
        "Baseline", 
        "Random Search", 
        "Bayesian Optimization (skopt)", 
        "Bayesian Optimization (GPyOpt)"
    ],
    "Neg. MSE": [
        baseline,
        -y_rs[-1] if y_rs is not None else None,
        -y_bo_skopt[-1],
        -y_bo_gpyopt[-1]
    ]
}

# Convertir a DataFrame
df_best_results = pd.DataFrame(best_results).round(3)
df_best_results
```

Este modelaje matemático y proceso de optimización garantiza que el problema de diabetes sea abordado de manera eficiente, maximizando el desempeño del modelo predictivo en validación cruzada.



### California Housing Prices

En este ejemplo, aplicaremos la optimización bayesiana a un problema de regresión de precios de vivienda en California. El conjunto de datos se puede descargar de [Kaggle](https://www.kaggle.com/camnugent/california-housing-prices) y contiene información sobre la población, los ingresos medios, los precios de las viviendas, etc. El objetivo, es predecir los precios de las viviendas en función de las características proporcionadas.

```{python, echo=FALSE}
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.ensemble import GradientBoostingRegressor 
from sklearn.model_selection import RandomizedSearchCV, cross_val_score
from scipy.stats import uniform

# Cargar el dataset de California Housing Prices
np.random.seed(0)
data_ch = fetch_california_housing()
X, Y = data_ch.data, data_ch.target  # X: características, Y: precios de vivienda
n_features_ch = X.shape[1]

# Instantiate an XGBRegressor with default hyperparameter settings
gbr_ch = GradientBoostingRegressor(n_estimators = 50, random_state = 0)

# and compute a baseline to beat with hyperparameter optimization 
baseline_ch = -cross_val_score(gbr_ch, X, Y, scoring='neg_mean_squared_error').mean()
```

#### Ajuste de hiperparámetros con búsqueda aleatoria

Para el ajuste de hiperparámetros con búsqueda aleatoria, utilizamos `RandomSearchCV` de scikit-learn y calculamos una puntuación de validación cruzada para cada punto seleccionado aleatoriamente en el espacio de hiperparámetros. El modelo utilizado fue `GradientBoostingRegressor` de scikit-learn.

```{python, echo=FALSE}
from scipy.stats import loguniform

np.random.seed(0)
# Hyperparameters to tune and their ranges
param_dist_ch = {'max_depth': range(1,5),
              'learning_rate': loguniform(10**-5,10**0),
              'max_features': range(1, n_features_ch),
              'min_samples_split': range(2 ,1000),
              'min_samples_leaf':range(1 ,1000)}

rs_ch = RandomizedSearchCV(gbr_ch, param_distributions = param_dist_ch, 
                        scoring='neg_mean_squared_error', n_iter=25)

# Run random search for 25 iterations
rs_ch.fit(X, Y);
```

#### Ajuste de hiperparámetros con optimización bayesiana

Para ajustar los hiperparámetros con optimización bayesiana, implementamos una función objetivo `cv_score` que toma los hiperparámetros como entrada y devuelve una puntuación de validación cruzada. El modelo, empleado fue `GradientBoostingRegressor` de scikit-learn.

```{python, echo=FALSE}
import numpy as np
from sklearn.datasets import fetch_california_housing
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import cross_val_score
from GPyOpt.methods import BayesianOptimization

np.random.seed(0)
# Definir el espacio de búsqueda para la optimización bayesiana
bds_chbo = [
    {'name': 'learning_rate', 'type': 'continuous', 'domain': (10**-5, 10**0)},
    {'name': 'max_features', 'type': 'discrete', 'domain': list(range(1, n_features_ch + 1))},
    {'name': 'max_depth', 'type': 'discrete', 'domain': list(range(1, 6))},
    {'name': 'min_samples_split', 'type': 'discrete', 'domain': list(range(2, 1001))},
    {'name': 'min_samples_leaf', 'type': 'discrete', 'domain': list(range(1, 1001))}
]

# Definir el objetivo para la optimización
def cv_score(parameters):
    # Los parámetros se pasan como una lista de listas
    parameters = parameters[0]
    # Crear el modelo con los hiperparámetros
    gbr = GradientBoostingRegressor(
        learning_rate=parameters[0],
        max_features=int(parameters[1]),
        max_depth=int(parameters[2]),
        min_samples_split=int(parameters[3]),
        min_samples_leaf=int(parameters[4]),
        n_estimators=50,  # Puedes ajustar si quieres más árboles
        random_state=0
    )
    # Calcular el puntaje con validación cruzada
    score = -np.mean(cross_val_score(gbr, X, Y, cv=5, scoring="neg_mean_squared_error", n_jobs=-1))
    return score

# Configurar el optimizador bayesiano
optimizer_chbo = BayesianOptimization(
    f=cv_score, 
    domain=bds_chbo,
    model_type='GP',
    acquisition_type='EI',
    acquisition_jitter=0.05,
    exact_feval=True,
    maximize=False  # Minimizar el MSE
)

# Ejecutar la optimización (20 iteraciones)
optimizer_chbo.run_optimization(max_iter=20)

# Mostrar los mejores resultados
#print("Mejores hiperparámetros encontrados:")
#print(f"Learning rate: {optimizer_chbo.X[np.argmin(optimizer_chbo.Y), 0]:.5f}")
#print(f"Max features: {int(optimizer_chbo.X[np.argmin(optimizer_chbo.Y), 1])}")
#print(f"Max depth: {int(optimizer_chbo.X[np.argmin(optimizer_chbo.Y), 2])}")
#print(f"Min samples split: {int(optimizer_chbo.X[np.argmin(optimizer_chbo.Y), 3])}")
#print(f"Min samples leaf: {int(optimizer_chbo.X[np.argmin(optimizer_chbo.Y), 4])}")
#print(f"Mejor MSE (negativo): {np.min(optimizer_chbo.Y):.4f}")
```

```{python, echo=FALSE}
# Comparar resultados de Random Search y Bayesian Optimization
y_rs_ch = -np.maximum.accumulate(rs_ch.cv_results_['mean_test_score'])
y_bo_chbo = -np.maximum.accumulate(-optimizer_chbo.Y).ravel()

print(f'Baseline neg. MSE = {baseline_ch:.5f}')
print(f'Random search neg. MSE = {y_rs_ch[-1]:.5f}')
print(f'Bayesian optimization GPyOpt neg. MSE = {y_bo_chbo[-1]:.5f}')
```

```{python, echo=FALSE}
# Graficar los resultados
plt.figure(figsize=(6, 4))
if y_rs_ch is not None:
    plt.plot(y_rs_ch, 'ro-', label='Random search')
plt.plot(y_bo_chbo, 'bo-', label='Bayesian optimization GPyOpt')
plt.xlabel('Iteration')
plt.ylabel('Neg. MSE')
plt.title('Value of the Best Sampled CV Score')
plt.legend()
plt.show()

```



```{python, echo=FALSE}
from sklearn.datasets import fetch_california_housing
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import cross_val_score, RandomizedSearchCV
from skopt import gp_minimize
from skopt.space import Real, Integer
from skopt.utils import use_named_args
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import uniform

# Cargar el dataset de California Housing Prices
np.random.seed(0)
data_h = fetch_california_housing()
X, Y = data_h.data, data_h.target
n_features_hs = X.shape[1]

# Modelo base para comparación
gbr_hs = GradientBoostingRegressor(n_estimators=50, random_state=0)

# Evaluar el modelo base utilizando validación cruzada
baseline_hs = -cross_val_score(gbr_hs, X, Y, scoring='neg_mean_squared_error', cv=5).mean()
#print(f'Baseline neg. MSE = {baseline_hs:.5f}')

# Definir el espacio de búsqueda para skopt
search_space_hs = [
    Real(0.01, 1.0, name='learning_rate'),        # Tasa de aprendizaje
    Integer(1, n_features_hs, name='max_features'),  # Número máximo de características
    Integer(1, 5, name='max_depth'),              # Profundidad máxima de los árboles
    Integer(2, 1000, name='min_samples_split'),   # Mínimo número de muestras para dividir
    Integer(1, 1000, name='min_samples_leaf')     # Mínimo número de muestras en las hojas
]

# Función objetivo para skopt
@use_named_args(search_space_hs)
def objective(learning_rate, max_features, max_depth, min_samples_split, min_samples_leaf):
    model = GradientBoostingRegressor(
        learning_rate=learning_rate,
        max_features=max_features,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        min_samples_leaf=min_samples_leaf,
        n_estimators=50,
        random_state=0
    )
    score = -cross_val_score(model, X, Y, scoring='neg_mean_squared_error', cv=5, n_jobs=-1).mean()
    return score

# Ejecutar la optimización bayesiana con skopt
result_hs = gp_minimize(
    func=objective,                   # Función objetivo
    dimensions=search_space_hs,          # Espacio de búsqueda
    acq_func='EI',                    # Expected Improvement
    n_calls=25,                       # Número de iteraciones
    n_initial_points=5,               # Puntos iniciales aleatorios
    random_state=0                   # Reproducibilidad
)

# Resultados de skopt
best_params_hs = {dim.name: val for dim, val in zip(search_space_hs, result_hs.x)}
#print("Best parameters from Bayesian optimization (skopt):")
#print(best_params_hs)
#print(f"Best neg. MSE from skopt: {result_hs.fun:.5f}")

# Comparar con RandomizedSearchCV
# Definir hiperparámetros y sus distribuciones para Random Search
param_dist_hs = {
    "learning_rate": uniform(0.01, 1),
    "max_features": range(1, n_features_hs + 1),
    "max_depth": range(1, 6),
    "min_samples_split": range(2, 1001),
    "min_samples_leaf": range(1, 1001)
}

# Graficar los resultados
# Máximos acumulados de cada iteración
y_bo_hs = -np.maximum.accumulate(-np.array(result_hs.func_vals))

# Plotear la comparación
plt.figure(figsize=(6, 4))
plt.plot(y_rs_ch, 'ro-', label='Random search')
plt.plot(y_bo_hs, 'bo-', label='Bayesian optimization (skopt)')
plt.xlabel('Iteration')
plt.ylabel('Neg. MSE')
plt.title('Value of the best sampled CV score')
plt.legend()
plt.show()
```

```{python, echo=FALSE}
import pandas as pd

#y_rs_ch = -np.maximum.accumulate(rs_ch.cv_results_['mean_test_score'])

# Comparar los resultados de Random Search y Bayesian Optimization
best_results_ho = {
    "Method": [
        "Baseline", 
        "Random Search", 
        "Bayesian Optimization (skopt)", 
        "Bayesian Optimization (GPyOpt)"
    ],
    "Neg. MSE": [
        baseline_hs,
        y_rs_ch[-1] if y_rs_ch[-1] is not None else None,
        result_hs.fun,
        np.min(optimizer_chbo.Y)
    ]
}

# Convertir a DataFrame
df_best_resch = pd.DataFrame(best_results_ho).round(5)
df_best_resch
```


### Red Neuronal para MNIST
En este ejemplo, el conjunto de datos MINST se utiliza para aplicar la optimización bayesiana para los hiperparámetros de una red neuronal NN.\ La biblioteca *tensorflow* se utiliza para definir la NN. *Tensorflow* contiene el conjunto de datos MNIST que contiene números escritos a mano en escala de grises del 0 al 9. Todas las imágenes están etiquetadas y, por lo tanto, se puede aplicar una estrategia de entrenamiento supervisada.\ Además, se importa la biblioteca *GPyOpt* para optimizar los hiperparámetros utilizando el *proceso gaussiano*. GPyOpt es una biblioteca de Python para la optimización bayesiana utilizando procesos gaussianos (GP). Está diseñada para ayudar a optimizar funciones costosas de evaluar, especialmente aquellas que no son convexas, ruidosas o de caja negra (donde se desconoce el mecanismo interno de la función). La biblioteca aprovecha los GP para modelar la función objetivo y proporciona métodos eficientes para explorar el espacio de búsqueda.

**Definition del problema**
La tarea de entrenar una red neuronal (NN) requiere la definición del model con diferentes hiperparametros como el learning rate o el numero de neuronas por capa. Con el método Bayesiano de opitmización se puede encontrar la mejor configuración de este modelo.

**Enfoque de optimización**

Se utiliza la optimización bayesiana para encontrar los mejores valores del model NN. Este enfoque construye un modelo probabilístico (Proceso Gaussiano) para aproximar la relación entre los hiperparámetros y la función objetivo (MSE). La técnica, guía la búsqueda hacia regiones prometedoras del espacio de hiperparámetros.

**Posibles aplicaciones**
Un modelo entrenado puede utilizarse para detectar escritura a mano y convertirla en escritura de imprenta estándar. El conjunto de datos debe ampliarse a letras escritas a mano y, tal vez, a caracteres especiales, pero una red neuronal como la utilizada en este proyecto debería gestionar esto fácilmente. Otra aplicación, que también contempla la ampliación de letras, es la detección de matrículas de automóviles en las rutas de tráfico para identificar vehículos que superan los límites de velocidad.


```{python, echo=FALSE}
import numpy as np
import matplotlib.pyplot as plt

## necessary libraries to build model tensorflow (objective funciton)
import tensorflow as tf
from keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.callbacks import ModelCheckpoint
import GPyOpt
```

**Cargar y preparar el conjunto de datos**
 Es necesario cargar el conjunto de datos. El conjunto de datos contiene 70 000 imágenes de números escritos a mano del 0 al 9. Cada imagen es una matriz de 28 x 28 píxeles. Cada píxel puede obtener un valor entre 0 (que corresponde al color negro) y 255 (que corresponde al color blanco). Por lo tanto, los datos de entrada se normalizan dividiéndolos por 255. La señal de salida contiene el número correspondiente del 0 al 9. El conjunto de datos se divide en 60 000 imágenes para entrenar el modelo y 10 000 imágenes para validarlo.
 
```{python, echo=FALSE}
# Load MNIST dataset
# Split into training and testing datasets
(X_train, y_train), (X_val, y_val) = mnist.load_data()
X_train = X_train.astype('float32') / 255
X_val = X_val.astype('float32') / 255
X_train.shape
```
Como la salida es una variable categórica, se aplica el método One-Shot con diez categorías o clases, cada una para cada número entre 0 y 9. Los números numéricos deben estar categóricos.

```{python, echo=FALSE}
y_train = tf.keras.utils.to_categorical(y_train, num_classes = 10)
y_val = tf.keras.utils.to_categorical(y_val, num_classes = 10)
```
La siguiente figura ilustra los datos: los valores X son matrices de 28 x 28 píxeles con un número escrito a mano, los valores Y correspondientes contienen el número.

```{python, echo=FALSE}
import matplotlib.pyplot as plt
m = X_train.shape
plt.subplot(1,3,1)
plt.imshow(X_train[3])
plt.title("y-train category: " + str(y_train[3]))
plt.subplot(1,3,3)
plt.imshow(X_val[1])
plt.title("y-val category: " + str(y_val[1]))
plt.show()
```

**Descripción del modelo (La función objetivo)** 
La siguiente imagen muestra una posible estructura de una red neuronal (NN). La red tiene una capa de entrada. En el caso del conjunto MNIST, las entradas son la imagen 28 x 28. La NN no puede recibir entradas en formato de matriz. Por lo tanto, la matriz se convierte en un vector con 784 elementos (28 x 28). Todas las entradas se envían a la primera capa oculta que contiene una cantidad de neuronas. La salida de estas neuronas son las entradas de la segunda capa con una cantidad definida de neuronas. La cantidad de neuronas de ambas capas no es necesariamente igual. La última capa se denomina capa de salida y debe tener 10 neuronas, una por cada cantidad posible. Cada entrada está conectada a cada neurona de la siguiente capa. Las entradas se multiplican por un peso $w$ y la suma de todas las entradas ponderadas se calcula como la salida de la neurona.
$$
y_{jk} = \sum_{i=1}^N {w_i x_i}
$$
con j el número de capa y k el número de neurona en la capa j La función de activación en cada capa oculta es Unidad Lineal Rectificada (relu) una función lineal para valores mayores o iguales a 0 y 0 para valores negativos. Durante la fase de entrenamiento, la NN se entrena para identificar la interpretación correcta de la imagen. Para ello, la red optimiza los pesos $w_{ik}$ aplicando un método llamado Backpropagation.
### Backpropagation
Los datos de entrada fluyen a través de la red capa por capa, aplicando pesos y sesgos, y activando funciones hasta que se genera la salida. Luego, la función de pérdida compara la salida predicha de la red con el objetivo real (por ejemplo, el error cuadrático medio para la regresión). Luego, se calcula el gradiente de la pérdida con respecto a los pesos y sesgos en la capa de salida utilizando la regla de la cadena del cálculo. Esta es la derivada de la función de pérdida con respecto a las activaciones de la última capa. Los gradientes se propagan hacia atrás desde la salida a las capas de entrada utilizando la regla de la cadena. Para cada neurona, se calcula cuánto contribuyó al error en la siguiente capa. Luego, cada peso $w$ y sesgo $b$ utilizando una regla como el Descenso de gradiente:
$$ 
w = w − η ⋅  \frac{∂w}{∂L} 

$$

$$ 
𝑏 = 𝑏 −𝜂⋅\frac{∂𝐿}{∂𝑏} 
$$
- η es el learning rate
- $\frac{∂w}{∂L}$ el gradiente de pérdida con respecto al peso $w$.\ 
Este proceso se repite a lo largo de varias épocas hasta que la función de pérdida mejora significativamente.

![Comparativo de enfoques para búsqueda de hiperpárametros](imgs/NN Structure.png)

Para ejecutar la optimización, es necesario implementar la creación de una estructura NN de manera que los parámetros de interés puedan variarse automáticamente. Los parámetros de interés son los siguientes:
- *learning rate*: controla cuánto ajustar los pesos del modelo con respecto al gradiente de pérdida, típicamente 1e-5, 1e-1.
- *número de unidades (neuronas) en la capa 1*: indica el número de neuronas en la capa, los valores típicos son 16, 32, 64, 128 y 256.
- *número de unidades (neuronas) en la capa 2*: indica el número de neuronas en la capa, los valores típicos son 16, 32, 64, 128 y 256.
- *l2_reg: el regularizador del núcleo*: agrega una penalización a la función de pérdida para pesos grandes, lo que alienta al modelo a encontrar pesos más pequeños, típicamente 1e-6, 1e-2.
- *batch_size*: el tamaño del lote es la cantidad de imágenes analizadas en una ejecución, generalmente 16, 32, 64, 128.

#### Ajuste de hiperparámetros
La función *build_model()* construye un modelo secuencial NN. Primero, se agrega la función *Flatten()* que toma la entrada de la matriz n x m y la convierte en un vector a de n*n elementos. Las siguientes dos capas son las capas ocultas y la capa de salida contiene 10 neuronas, cada una para un número. Los parámetros de entrada de la función son los parámetros de interés.

```{python, echo=FALSE}
# define the model as objective function()
def build_model(learning_rate, units_layer01,units_layer02, l2_reg):
    model = Sequential()
    model.add(Flatten(input_shape=(28,28)))
    model.add(Dense(units=units_layer01, activation='relu', kernel_regularizer=l2(l2_reg)))
    model.add(Dense(units=units_layer02, activation='relu', kernel_regularizer=l2(l2_reg)))
    model.add(Dense(units=10, activation='softmax'))
    return model
```

La función *model_score()* recibe una lista con el parámetro de interés y llama a la función *build_model()*. El modelo NN se parametriza con las diferentes variaciones de los parámetros de interés, se compila y ajusta con los datos de entrenamiento y se valida con los datos de validación. El tamaño del lote también varía. Como criterio, se selecciona y almacena el error cuadrático medio (mse).\ Además, se recomienda incluir *callbacks* durante el proceso de ajuste. En este caso, se implementan *EarlyStopping* y *ModelCheckpoints*. *EarlyStopping* monitorea la métrica, en este caso el **mse** y se detiene antes si se alcanza un valor definido. Esto evita el sobreajuste. *ModelCheckpoints* almacena los mejores valores del parámetro de interés para cada época.

```{python, echo=FALSE}
def model_score(params):
    learning_rate = float(params[:, 0])
    units_layer01 = int(params[:, 1])
    units_layer02 = int(params[:, 2])
    l2_reg = float(params[:, 3])
    batch_size = int(params[:, 4])

    model = build_model(learning_rate, units_layer01,units_layer02,  l2_reg)
    #model.summary()
    checkpoint_folder = "checkpoints/"
    checkpoint_path = checkpoint_folder +  f'checkpoint_lr_{learning_rate}_units_layer01_{units_layer01}_units_layer02_{units_layer02}_l2_{l2_reg}_batch_{batch_size}.keras' #h5
    callbacks = [
        EarlyStopping(monitor='val_mse', patience=15, restore_best_weights=True),
        ModelCheckpoint(checkpoint_path, monitor='val_mse', save_best_only=True, verbose=1)
    ]
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss='categorical_crossentropy',
                  metrics=['mse'])
    
    history = model.fit(X_train, y_train,
                        validation_data=(X_val, y_val),
                        batch_size=batch_size,
                        epochs=50,
                        callbacks=callbacks,
                        verbose=0)
    
    val_mse = np.max(history.history['val_mse'])
    return -val_mse

```

**Optimización Bayesiana (MNIST)**
Para ejecutar el optimizador, se deben definir los parámetros de interés y su rango. En este caso se utilizan los valores típicos mencionados anteriormente. Una vez definidos los parámetros, se utiliza el método de Optimización Bayesiana de GPyOpt para ejecutar el modelo dentro de los rangos de parámetros definidos llamando a la función *model_score*. El tipo de adquisición se define como "Expected Improvement" (EI).

Ahora se inicia la optimización con un número máximo de ejecuciones. En este caso, 35.

```{python, echo=FALSE}
# Define the bounds of the hyperparameters
bounds = [
    {'name': 'learning_rate', 'type': 'continuous', 'domain': (1e-5, 1e-1)},
    {'name': 'units_layer01', 'type': 'discrete', 'domain': (16, 32, 64, 128, 256)},
    {'name': 'units_layer02', 'type': 'discrete', 'domain': (16, 32, 64, 128, 256)},
    {'name': 'l2_reg', 'type': 'continuous', 'domain': (1e-6, 1e-2)},
    {'name': 'batch_size', 'type': 'discrete', 'domain': (16, 32, 64, 128)}
]

# Perform Bayesian Optimization
optimizer = GPyOpt.methods.BayesianOptimization(f=model_score, 
                                                domain=bounds, 
                                                acquisition_type='EI'  # Expected Improvement
)

```

```{python, echo=FALSE}
optimizer.run_optimization(max_iter=30, verbosity=True, eps=1e-6)
```

La siguiente figura muestra los resultados de **mse**. Están ordenados del peor al mejor y cada punto de valor contiene el número de ejecución para identificar los parámetros utilizados para obtener el valor.
Se selecciona el mejor modelo y se imprimen sus características.

```{python, echo=FALSE}
# Assuming optimizer.X and optimizer.Y are already defined
opt_res_param = optimizer.X
print(len(opt_res_param))
opt_res_score = optimizer.Y
opt_res_score = opt_res_score.flatten()

# Sort scores and retain original indices
original_indices = np.argsort(opt_res_score)[::-1]  # Indices for descending order
opt_res_score_sorted = opt_res_score[original_indices]
idx_opt_value = original_indices[len(original_indices)-1]


# Create N array (1 to len(opt_res_score_sorted))
N = np.arange(0, len(opt_res_score_sorted) )

# Set up the figure size
plt.figure(figsize=(16, 6))  # Width: 10 inches, Height: 6 inches

# Plot scores
plt.plot(N, opt_res_score_sorted, 'g*-', label="Sorted Scores with run number")  # Add a label for the legend
plt.grid()

# Annotate with original run numbers
for i, idx in enumerate(original_indices):
    plt.annotate(f"{idx+1}", (N[i], opt_res_score_sorted[i]), textcoords="offset points", xytext=(5, 5), ha='center')

# Add labels, title, and legend
plt.xlabel("Rank", fontsize=12)
plt.ylabel("Score", fontsize=12)
plt.title("Sorted Scores with Run Numbers", fontsize=14)
plt.legend(loc="upper right", fontsize=10)  # Add a legend at the top right

# Show the plot
plt.show()
```

```{python, echo=FALSE}
from tensorflow.keras.models import load_model
import os
import re

# 
folder_path = "checkpoints/"
opt_models = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]
opt_models_sorted = sorted(opt_models , key=os.path.getctime, reverse=True)
opt_idx_model = original_indices[len(opt_models_sorted) - len(original_indices)-1]
best_fitting_model_file = opt_models_sorted[len(original_indices)-idx_opt_value-1]
#
model = load_model(best_fitting_model_file)
print(' best fitting model: ')
print(best_fitting_model_file)
# Inspect the model
model.summary()



# read learning rate (lr), regulator 2 and batch size

# Regular expressions for lr, l2, and batch
lr_match = re.search(r"lr_([0-9.]+)", best_fitting_model_file)
l2_match = re.search(r"l2_([0-9.]+)", best_fitting_model_file)
batch_match = re.search(r"batch_([0-9]+)", best_fitting_model_file)

# Extract values
lr = float(lr_match.group(1)) if lr_match else None
l2 = float(l2_match.group(1)) if l2_match else None
batch = int(batch_match.group(1)) if batch_match else None

# Print the results
print(f"Learning Rate (lr): {lr}")
print(f"L2 Regularization (l2): {l2}")
print(f"Batch Size (batch): {batch}")


```

**Optimización Random Search (MNIST)**


#### Resultados 

# Fuentes
- [#] Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) “Least Angle Regression,” Annals of Statistics (with discussion), 407-499. (https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)
- [#] Davis Joseph, https://www.linkedin.com/pulse/optimizing-machine-learning-models-bayesian-deep-dive-davis-joseph-qsqje?utm_source=share&utm_medium=member_android&utm_campaign=share_via, published 18/08/2024
