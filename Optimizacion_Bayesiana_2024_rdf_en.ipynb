{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The finding of adequate hyper parameters is crucial to improve the performance and generalization of machine learning models. There are several methods described in modern literature that can help to find the best fitting hyper parameters. The performance is tested in different dataset that are tested and well studied, such as MINST. Hyper parameters (HP) are external to the learning process but significantly impact model performance. HP are external to the learning process but significantly impact model performance. Effective tuning typically requires domain expertise or computationally expensive methods like brute-force search.\n",
    "Effective tuning typically requires domain expertise or computationally expensive methods like brute-force search In [1, 2, 3], the Bayesian optimization is explored.  Bayesian optimization leverages prior knowledge to update posterior distributions based on sample data, guiding the search for optimal hyperparameter configurations efficiently. Traditional approaches like grid search and random search are computationally expensive and less effective in high-dimensional spaces. Bayesian optimization offers a more efficient alternative, particularly for expensive, black-box objective functions. \n",
    "In [1] the use of Bayesian optimization is explored for tuning hyper parameters in machine learning models, which is critical for improving model performance. The study proposes a method using Bayesian optimization with Gaussian processes. Traditional approaches like grid search and random search are computationally expensive and less effective in high-dimensional spaces. Bayesian optimization offers a more efficient alternative, particularly for expensive, black-box objective functions. The results were conducted on machine learning models like random forests, neural networks (CNN and RNN), and deep forests (gcForest). Bayesian optimization demonstrated significant improvements in prediction accuracy and computational efficiency compared to traditional methods.The results confirm that Bayesian optimization outperforms other optimization techniques in terms of speed and achieving better model performance, especially in scenarios with limited computational resources or high-dimensional hyperparameter spaces.\n",
    "\n",
    "In [2] it is stated that complex models like Deep Belief Networks (DBNs) have numerous hyper parameters, making manual optimization inefficient and inconsistent.\n",
    "The difficulty in tuning these models hinders reproducibility and progress in machine learning research. Therefore, the proposed approaches is based on\n",
    "Random Search, a method where hyper parameters are sampled randomly from predefined distributions. It is efficient for simple problems but struggles with complex models like DBNs. In order to improve this disadvantage, the Sequential Model-Based Optimization is introduced.\n",
    "This method approximates the loss function with a surrogate model to guide the search. Two specific variants of the methods are explained: Gaussian Process and the\n",
    "Tree-Structured Parzen Estimator. Both methods were tested on DBNs with up to 32 hyper parameters across tasks like image classification on datasets such as MNIST and MRBI. The results show, that Random search matched human manual optimization for simple tasks but failed for harder datasets.\n",
    "Tree-Structured Parzen Estimator consistently outperformed both random search and manual tuning, achieving better accuracy and efficiency.The Gaussian Process was effective but less efficient than TPE due to computational overhead.\n",
    "\n",
    "In [3], the results proves that experiments were conducted on machine learning models like random forests, neural networks (CNN and RNN), and deep forests (gcForest). Bayesian optimization demonstrated significant improvements in prediction accuracy and computational efficiency compared to traditional methods.\n",
    "The results confirm that Bayesian optimization outperforms other optimization techniques in terms of speed and achieving better model performance, especially in scenarios with limited computational resources or high-dimensional hyperparameter spaces.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[1] Hyunghun Cho et al.: *Basic Enhancement Strategies When Using Bayesian Optimization for Hyperparameter Tuning of Deep Neural Networks*, Special section on scalable deeo learning for big data, VOLUME 8, Digital Object Identifier 10.1109/ACCESS.2020.2981072, pp. 52588-52608 IEEE Access, 2020\n",
    "\n",
    "[2] James Bergstra et al: *Algorithms for Hyper-Parameter Optimization*, NIPS'11: Proceedings of the 24th International Conference on Neural Information Processing Systems,  pp. 2546 - 2554, 2011\n",
    "\n",
    "[3] Jia Wu et al: *Hyperparameter Optimization for Machine Learning Models Based on Bayesian Optimization*, Journal of Electronic Science , VOL. 17, NO. 1,Digital Object Identifier:10.11989/JEST.1674-862X.80904120, pp.26 - 40, 2019, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep data and environment and Import MINST dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real\n",
    "from skopt import BayesSearchCV\n",
    "from skopt import gp_minimize\n",
    "# objective function\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "## necessary libraries to build model tensorflow (objective funciton)\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import GPyOpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "# Split into training and testing datasets\n",
    "(X_train, y_train), (X_val, y_val) = mnist.load_data()\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_val = X_val.astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes = 10)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html\\\n",
    "https://scikit-optimize.github.io/stable/auto_examples/bayesian-optimization.html#sphx-glr-auto-examples-bayesian-optimization-py\\\n",
    "https://www.linkedin.com/pulse/optimizing-machine-learning-models-bayesian-deep-dive-davis-joseph-qsqje?utm_source=share&utm_medium=member_android&utm_campaign=share_via\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model as objective function()\n",
    "def build_model(learning_rate, units_layer01,units_layer02, l2_reg):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28,28)))\n",
    "    model.add(Dense(units=units_layer01, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "    model.add(Dense(units=units_layer02, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_score(params):\n",
    "    learning_rate = float(params[:, 0])\n",
    "    units_layer01 = int(params[:, 1])\n",
    "    units_layer02 = int(params[:, 2])\n",
    "    l2_reg = float(params[:, 3])\n",
    "    batch_size = int(params[:, 4])\n",
    "\n",
    "    model = build_model(learning_rate, units_layer01,units_layer02,  l2_reg)\n",
    "    #model.summary()\n",
    "    checkpoint_folder = \"checkpoints/\"\n",
    "    checkpoint_path = checkpoint_folder +  f'checkpoint_lr_{learning_rate}_units_layer01_{units_layer01}_units_layer02_{units_layer02}_l2_{l2_reg}_batch_{batch_size}.keras' #h5\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_mse', patience=15, restore_best_weights=True),\n",
    "        ModelCheckpoint(checkpoint_path, monitor='val_mse', save_best_only=True, verbose=1)\n",
    "    ]\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['mse'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=50,\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=0)\n",
    "    \n",
    "    val_mse = np.max(history.history['val_mse'])\n",
    "    return -val_mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train category [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_val category: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "m = X_train.shape\n",
    "print(m)\n",
    "plt.imshow(X_train[3])\n",
    "plt.show()\n",
    "print(\"y_train category\", y_train[3])\n",
    "plt.imshow(X_val[1])\n",
    "plt.show()\n",
    "print(\"y_val category:\", y_val[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_mse improved from inf to 0.09028, saving model to checkpoints/checkpoint_lr_0.08723775514781722_units_layer01_128_units_layer02_16_l2_0.005574673782382699_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.09028\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.09028\n",
      "\n",
      "Epoch 4: val_mse improved from 0.09028 to 0.09019, saving model to checkpoints/checkpoint_lr_0.08723775514781722_units_layer01_128_units_layer02_16_l2_0.005574673782382699_batch_16.keras\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.09019\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.09019\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.09019\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.09019\n",
      "\n",
      "Epoch 9: val_mse improved from 0.09019 to 0.09013, saving model to checkpoints/checkpoint_lr_0.08723775514781722_units_layer01_128_units_layer02_16_l2_0.005574673782382699_batch_16.keras\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.09013\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.09013\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.09013\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.09013\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.09013\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.09013\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.09013\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.09013\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.09013\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.09013\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.09013\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.09013\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.09013\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.09013\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.09013\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.02597, saving model to checkpoints/checkpoint_lr_0.0849140455473568_units_layer01_32_units_layer02_32_l2_0.001797116706481264_batch_128.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.02597\n",
      "\n",
      "Epoch 3: val_mse improved from 0.02597 to 0.02445, saving model to checkpoints/checkpoint_lr_0.0849140455473568_units_layer01_32_units_layer02_32_l2_0.001797116706481264_batch_128.keras\n",
      "\n",
      "Epoch 4: val_mse improved from 0.02445 to 0.02243, saving model to checkpoints/checkpoint_lr_0.0849140455473568_units_layer01_32_units_layer02_32_l2_0.001797116706481264_batch_128.keras\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.02243\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.02243\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.02243\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.02243\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.02243\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.02243\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.02243\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.02243\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.02243\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.02243\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.02243\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.02243\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.02243\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.02243\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.02243\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.02415, saving model to checkpoints/checkpoint_lr_0.046498561621994526_units_layer01_128_units_layer02_64_l2_0.004162668154311232_batch_128.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.02415 to 0.02017, saving model to checkpoints/checkpoint_lr_0.046498561621994526_units_layer01_128_units_layer02_64_l2_0.004162668154311232_batch_128.keras\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.02017\n",
      "\n",
      "Epoch 4: val_mse improved from 0.02017 to 0.01805, saving model to checkpoints/checkpoint_lr_0.046498561621994526_units_layer01_128_units_layer02_64_l2_0.004162668154311232_batch_128.keras\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.01805\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.01805\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.01805\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.01805\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.01805\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.01805\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.01805\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.01805\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.01805\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.01805\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.01805\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.01805\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.01805\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.01805\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.01805\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.09025, saving model to checkpoints/checkpoint_lr_0.09784424829768311_units_layer01_64_units_layer02_32_l2_0.007957802986034447_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.09025 to 0.09018, saving model to checkpoints/checkpoint_lr_0.09784424829768311_units_layer01_64_units_layer02_32_l2_0.007957802986034447_batch_16.keras\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.09018\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.09018\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.09018\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.09018\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.09018\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.09018\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.09018\n",
      "\n",
      "Epoch 10: val_mse improved from 0.09018 to 0.09003, saving model to checkpoints/checkpoint_lr_0.09784424829768311_units_layer01_64_units_layer02_32_l2_0.007957802986034447_batch_16.keras\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.03165, saving model to checkpoints/checkpoint_lr_0.05438072263189594_units_layer01_32_units_layer02_64_l2_0.008403859810931459_batch_64.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.03165\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.03165\n",
      "\n",
      "Epoch 4: val_mse improved from 0.03165 to 0.03075, saving model to checkpoints/checkpoint_lr_0.05438072263189594_units_layer01_32_units_layer02_64_l2_0.008403859810931459_batch_64.keras\n",
      "\n",
      "Epoch 5: val_mse improved from 0.03075 to 0.02749, saving model to checkpoints/checkpoint_lr_0.05438072263189594_units_layer01_32_units_layer02_64_l2_0.008403859810931459_batch_64.keras\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.02749\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.02749\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.02749\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.02749\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.02749\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.02749\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.02749\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.02749\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.02749\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.02749\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.02749\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.02749\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.02749\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.02749\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.02749\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.05314, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.05314 to 0.03048, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 3: val_mse improved from 0.03048 to 0.02259, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 4: val_mse improved from 0.02259 to 0.01902, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 5: val_mse improved from 0.01902 to 0.01701, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 6: val_mse improved from 0.01701 to 0.01568, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 7: val_mse improved from 0.01568 to 0.01479, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 8: val_mse improved from 0.01479 to 0.01400, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 9: val_mse improved from 0.01400 to 0.01346, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 10: val_mse improved from 0.01346 to 0.01299, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 11: val_mse improved from 0.01299 to 0.01260, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 12: val_mse improved from 0.01260 to 0.01227, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 13: val_mse improved from 0.01227 to 0.01194, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 14: val_mse improved from 0.01194 to 0.01165, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 15: val_mse improved from 0.01165 to 0.01142, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 16: val_mse improved from 0.01142 to 0.01121, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 17: val_mse improved from 0.01121 to 0.01097, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 18: val_mse improved from 0.01097 to 0.01077, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 19: val_mse improved from 0.01077 to 0.01053, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 20: val_mse improved from 0.01053 to 0.01039, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 21: val_mse improved from 0.01039 to 0.01024, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 22: val_mse improved from 0.01024 to 0.01006, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 23: val_mse improved from 0.01006 to 0.00991, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 24: val_mse improved from 0.00991 to 0.00977, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 25: val_mse improved from 0.00977 to 0.00962, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 26: val_mse improved from 0.00962 to 0.00947, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 27: val_mse improved from 0.00947 to 0.00936, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 28: val_mse improved from 0.00936 to 0.00924, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 29: val_mse improved from 0.00924 to 0.00911, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 30: val_mse improved from 0.00911 to 0.00900, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 31: val_mse improved from 0.00900 to 0.00889, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 32: val_mse improved from 0.00889 to 0.00882, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 33: val_mse improved from 0.00882 to 0.00868, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 34: val_mse improved from 0.00868 to 0.00860, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 35: val_mse improved from 0.00860 to 0.00852, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 36: val_mse improved from 0.00852 to 0.00839, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 37: val_mse improved from 0.00839 to 0.00830, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 38: val_mse improved from 0.00830 to 0.00824, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 39: val_mse improved from 0.00824 to 0.00812, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 40: val_mse improved from 0.00812 to 0.00808, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 41: val_mse improved from 0.00808 to 0.00797, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 42: val_mse improved from 0.00797 to 0.00792, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 43: val_mse improved from 0.00792 to 0.00782, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 44: val_mse improved from 0.00782 to 0.00775, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 45: val_mse improved from 0.00775 to 0.00768, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 46: val_mse improved from 0.00768 to 0.00762, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 47: val_mse improved from 0.00762 to 0.00755, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 48: val_mse improved from 0.00755 to 0.00750, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 49: val_mse improved from 0.00750 to 0.00741, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 50: val_mse improved from 0.00741 to 0.00735, saving model to checkpoints/checkpoint_lr_1e-05_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "num acquisition: 1, time elapsed: 901.06s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.09037, saving model to checkpoints/checkpoint_lr_0.0879583871589365_units_layer01_128_units_layer02_16_l2_0.006820125260818518_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.09037 to 0.09011, saving model to checkpoints/checkpoint_lr_0.0879583871589365_units_layer01_128_units_layer02_16_l2_0.006820125260818518_batch_16.keras\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.09011\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.09011\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.09011\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.09011\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.09011\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.09011\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.09011\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.09011\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.09011\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.09011\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.09011\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.09011\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.09011\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.09011\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.09011\n",
      "num acquisition: 2, time elapsed: 1032.54s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.02487, saving model to checkpoints/checkpoint_lr_0.01156811859168441_units_layer01_128_units_layer02_16_l2_0.01_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.02487 to 0.02376, saving model to checkpoints/checkpoint_lr_0.01156811859168441_units_layer01_128_units_layer02_16_l2_0.01_batch_16.keras\n",
      "\n",
      "Epoch 3: val_mse improved from 0.02376 to 0.02079, saving model to checkpoints/checkpoint_lr_0.01156811859168441_units_layer01_128_units_layer02_16_l2_0.01_batch_16.keras\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.02079\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.02079\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.02079\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.02079\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.02079\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.02079\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.02079\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.02079\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.02079\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.02079\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.02079\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.02079\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.02079\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.02079\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.02079\n",
      "num acquisition: 3, time elapsed: 1117.39s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.09033, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_128_units_layer02_16_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.09033\n",
      "\n",
      "Epoch 3: val_mse improved from 0.09033 to 0.09028, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_128_units_layer02_16_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.09028\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.09028\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.09028\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.09028\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.09028\n",
      "\n",
      "Epoch 9: val_mse improved from 0.09028 to 0.09021, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_128_units_layer02_16_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 10: val_mse improved from 0.09021 to 0.09021, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_128_units_layer02_16_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.09021\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.09021\n",
      "\n",
      "Epoch 13: val_mse improved from 0.09021 to 0.09017, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_128_units_layer02_16_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.09017\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.09017\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.09017\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.09017\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.09017\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.09017\n",
      "\n",
      "Epoch 20: val_mse improved from 0.09017 to 0.09010, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_128_units_layer02_16_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 27: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 29: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 30: val_mse improved from 0.09010 to 0.09006, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_128_units_layer02_16_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 31: val_mse did not improve from 0.09006\n",
      "\n",
      "Epoch 32: val_mse did not improve from 0.09006\n",
      "\n",
      "Epoch 33: val_mse did not improve from 0.09006\n",
      "\n",
      "Epoch 34: val_mse did not improve from 0.09006\n",
      "\n",
      "Epoch 35: val_mse did not improve from 0.09006\n",
      "\n",
      "Epoch 36: val_mse did not improve from 0.09006\n",
      "\n",
      "Epoch 37: val_mse did not improve from 0.09006\n",
      "\n",
      "Epoch 38: val_mse did not improve from 0.09006\n",
      "\n",
      "Epoch 39: val_mse did not improve from 0.09006\n",
      "\n",
      "Epoch 40: val_mse did not improve from 0.09006\n",
      "\n",
      "Epoch 41: val_mse did not improve from 0.09006\n",
      "\n",
      "Epoch 42: val_mse did not improve from 0.09006\n",
      "\n",
      "Epoch 43: val_mse did not improve from 0.09006\n",
      "\n",
      "Epoch 44: val_mse did not improve from 0.09006\n",
      "\n",
      "Epoch 45: val_mse did not improve from 0.09006\n",
      "num acquisition: 4, time elapsed: 1325.19s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.07867, saving model to checkpoints/checkpoint_lr_0.07347249980764317_units_layer01_64_units_layer02_32_l2_0.01_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.07867 to 0.07727, saving model to checkpoints/checkpoint_lr_0.07347249980764317_units_layer01_64_units_layer02_32_l2_0.01_batch_16.keras\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.07727\n",
      "\n",
      "Epoch 4: val_mse improved from 0.07727 to 0.07706, saving model to checkpoints/checkpoint_lr_0.07347249980764317_units_layer01_64_units_layer02_32_l2_0.01_batch_16.keras\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.07706\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.07706\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.07706\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.07706\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.07706\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.07706\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.07706\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.07706\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.07706\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.07706\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.07706\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.07706\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.07706\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.07706\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.07706\n",
      "num acquisition: 5, time elapsed: 1398.16s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.02862, saving model to checkpoints/checkpoint_lr_0.023764460947961405_units_layer01_16_units_layer02_16_l2_0.005415978814116606_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.02862 to 0.02725, saving model to checkpoints/checkpoint_lr_0.023764460947961405_units_layer01_16_units_layer02_16_l2_0.005415978814116606_batch_16.keras\n",
      "\n",
      "Epoch 3: val_mse improved from 0.02725 to 0.02555, saving model to checkpoints/checkpoint_lr_0.023764460947961405_units_layer01_16_units_layer02_16_l2_0.005415978814116606_batch_16.keras\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.02555\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.02555\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.02555\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.02555\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.02555\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.02555\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.02555\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.02555\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.02555\n",
      "\n",
      "Epoch 13: val_mse improved from 0.02555 to 0.02524, saving model to checkpoints/checkpoint_lr_0.023764460947961405_units_layer01_16_units_layer02_16_l2_0.005415978814116606_batch_16.keras\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.02524\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.02524\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.02524\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.02524\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.02524\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.02524\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.02524\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.02524\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.02524\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.02524\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.02524\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.02524\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.02524\n",
      "\n",
      "Epoch 27: val_mse did not improve from 0.02524\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.02524\n",
      "num acquisition: 6, time elapsed: 1495.00s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.02112, saving model to checkpoints/checkpoint_lr_0.049691292027688114_units_layer01_64_units_layer02_32_l2_0.0007349640818751264_batch_64.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.02112\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.02112\n",
      "\n",
      "Epoch 4: val_mse improved from 0.02112 to 0.01899, saving model to checkpoints/checkpoint_lr_0.049691292027688114_units_layer01_64_units_layer02_32_l2_0.0007349640818751264_batch_64.keras\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.01899\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.01899\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.01899\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.01899\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.01899\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.01899\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.01899\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.01899\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.01899\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.01899\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.01899\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.01899\n",
      "\n",
      "Epoch 17: val_mse improved from 0.01899 to 0.01776, saving model to checkpoints/checkpoint_lr_0.049691292027688114_units_layer01_64_units_layer02_32_l2_0.0007349640818751264_batch_64.keras\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.01776\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.01776\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.01776\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.01776\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.01776\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.01776\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.01776\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.01776\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.01776\n",
      "\n",
      "Epoch 27: val_mse did not improve from 0.01776\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.01776\n",
      "\n",
      "Epoch 29: val_mse did not improve from 0.01776\n",
      "\n",
      "Epoch 30: val_mse did not improve from 0.01776\n",
      "\n",
      "Epoch 31: val_mse did not improve from 0.01776\n",
      "\n",
      "Epoch 32: val_mse did not improve from 0.01776\n",
      "num acquisition: 7, time elapsed: 1532.15s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.01996, saving model to checkpoints/checkpoint_lr_0.01557089783789828_units_layer01_64_units_layer02_128_l2_0.00424606876096885_batch_32.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.01996 to 0.01898, saving model to checkpoints/checkpoint_lr_0.01557089783789828_units_layer01_64_units_layer02_128_l2_0.00424606876096885_batch_32.keras\n",
      "\n",
      "Epoch 3: val_mse improved from 0.01898 to 0.01750, saving model to checkpoints/checkpoint_lr_0.01557089783789828_units_layer01_64_units_layer02_128_l2_0.00424606876096885_batch_32.keras\n",
      "\n",
      "Epoch 4: val_mse improved from 0.01750 to 0.01735, saving model to checkpoints/checkpoint_lr_0.01557089783789828_units_layer01_64_units_layer02_128_l2_0.00424606876096885_batch_32.keras\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.01735\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.01735\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.01735\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.01735\n",
      "\n",
      "Epoch 9: val_mse improved from 0.01735 to 0.01561, saving model to checkpoints/checkpoint_lr_0.01557089783789828_units_layer01_64_units_layer02_128_l2_0.00424606876096885_batch_32.keras\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.01561\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.01561\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.01561\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.01561\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.01561\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.01561\n",
      "\n",
      "Epoch 16: val_mse improved from 0.01561 to 0.01531, saving model to checkpoints/checkpoint_lr_0.01557089783789828_units_layer01_64_units_layer02_128_l2_0.00424606876096885_batch_32.keras\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.01531\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.01531\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.01531\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.01531\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.01531\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.01531\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.01531\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.01531\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.01531\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.01531\n",
      "\n",
      "Epoch 27: val_mse did not improve from 0.01531\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.01531\n",
      "\n",
      "Epoch 29: val_mse did not improve from 0.01531\n",
      "\n",
      "Epoch 30: val_mse did not improve from 0.01531\n",
      "\n",
      "Epoch 31: val_mse did not improve from 0.01531\n",
      "num acquisition: 8, time elapsed: 1597.28s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.02658, saving model to checkpoints/checkpoint_lr_0.014318994855456249_units_layer01_64_units_layer02_64_l2_0.009571611542503066_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.02658\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.02658\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.02658\n",
      "\n",
      "Epoch 5: val_mse improved from 0.02658 to 0.02512, saving model to checkpoints/checkpoint_lr_0.014318994855456249_units_layer01_64_units_layer02_64_l2_0.009571611542503066_batch_16.keras\n",
      "\n",
      "Epoch 6: val_mse improved from 0.02512 to 0.02119, saving model to checkpoints/checkpoint_lr_0.014318994855456249_units_layer01_64_units_layer02_64_l2_0.009571611542503066_batch_16.keras\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.02119\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.02119\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.02119\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.02119\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.02119\n",
      "\n",
      "Epoch 12: val_mse improved from 0.02119 to 0.02009, saving model to checkpoints/checkpoint_lr_0.014318994855456249_units_layer01_64_units_layer02_64_l2_0.009571611542503066_batch_16.keras\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.02009\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.02009\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.02009\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.02009\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.02009\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.02009\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.02009\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.02009\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.02009\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.02009\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.02009\n",
      "\n",
      "Epoch 24: val_mse improved from 0.02009 to 0.01856, saving model to checkpoints/checkpoint_lr_0.014318994855456249_units_layer01_64_units_layer02_64_l2_0.009571611542503066_batch_16.keras\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.01856\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.01856\n",
      "\n",
      "Epoch 27: val_mse did not improve from 0.01856\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.01856\n",
      "\n",
      "Epoch 29: val_mse did not improve from 0.01856\n",
      "\n",
      "Epoch 30: val_mse did not improve from 0.01856\n",
      "\n",
      "Epoch 31: val_mse did not improve from 0.01856\n",
      "\n",
      "Epoch 32: val_mse did not improve from 0.01856\n",
      "\n",
      "Epoch 33: val_mse did not improve from 0.01856\n",
      "\n",
      "Epoch 34: val_mse did not improve from 0.01856\n",
      "\n",
      "Epoch 35: val_mse did not improve from 0.01856\n",
      "\n",
      "Epoch 36: val_mse did not improve from 0.01856\n",
      "\n",
      "Epoch 37: val_mse did not improve from 0.01856\n",
      "\n",
      "Epoch 38: val_mse did not improve from 0.01856\n",
      "\n",
      "Epoch 39: val_mse did not improve from 0.01856\n",
      "num acquisition: 9, time elapsed: 1747.06s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.02555, saving model to checkpoints/checkpoint_lr_0.05656916830098021_units_layer01_128_units_layer02_32_l2_0.009550654961580349_batch_128.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.02555\n",
      "\n",
      "Epoch 3: val_mse improved from 0.02555 to 0.02477, saving model to checkpoints/checkpoint_lr_0.05656916830098021_units_layer01_128_units_layer02_32_l2_0.009550654961580349_batch_128.keras\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.02477\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.02477\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.02477\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.02477\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.02477\n",
      "\n",
      "Epoch 9: val_mse improved from 0.02477 to 0.02300, saving model to checkpoints/checkpoint_lr_0.05656916830098021_units_layer01_128_units_layer02_32_l2_0.009550654961580349_batch_128.keras\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.02300\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.02300\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.02300\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.02300\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.02300\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.02300\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.02300\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.02300\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.02300\n",
      "\n",
      "Epoch 19: val_mse improved from 0.02300 to 0.02255, saving model to checkpoints/checkpoint_lr_0.05656916830098021_units_layer01_128_units_layer02_32_l2_0.009550654961580349_batch_128.keras\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.02255\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.02255\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.02255\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.02255\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.02255\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.02255\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.02255\n",
      "\n",
      "Epoch 27: val_mse improved from 0.02255 to 0.02236, saving model to checkpoints/checkpoint_lr_0.05656916830098021_units_layer01_128_units_layer02_32_l2_0.009550654961580349_batch_128.keras\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.02236\n",
      "\n",
      "Epoch 29: val_mse did not improve from 0.02236\n",
      "\n",
      "Epoch 30: val_mse did not improve from 0.02236\n",
      "\n",
      "Epoch 31: val_mse did not improve from 0.02236\n",
      "\n",
      "Epoch 32: val_mse did not improve from 0.02236\n",
      "\n",
      "Epoch 33: val_mse did not improve from 0.02236\n",
      "\n",
      "Epoch 34: val_mse did not improve from 0.02236\n",
      "\n",
      "Epoch 35: val_mse did not improve from 0.02236\n",
      "\n",
      "Epoch 36: val_mse did not improve from 0.02236\n",
      "\n",
      "Epoch 37: val_mse did not improve from 0.02236\n",
      "\n",
      "Epoch 38: val_mse did not improve from 0.02236\n",
      "\n",
      "Epoch 39: val_mse did not improve from 0.02236\n",
      "\n",
      "Epoch 40: val_mse did not improve from 0.02236\n",
      "\n",
      "Epoch 41: val_mse did not improve from 0.02236\n",
      "\n",
      "Epoch 42: val_mse did not improve from 0.02236\n",
      "num acquisition: 10, time elapsed: 1799.62s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.08321, saving model to checkpoints/checkpoint_lr_0.09102464833032031_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.08321\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.08321\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.08321\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.08321\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.08321\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.08321\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.08321\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.08321\n",
      "\n",
      "Epoch 10: val_mse improved from 0.08321 to 0.08295, saving model to checkpoints/checkpoint_lr_0.09102464833032031_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.08295\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.08295\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.08295\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.08295\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.08295\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.08295\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.08295\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.08295\n",
      "\n",
      "Epoch 19: val_mse improved from 0.08295 to 0.08270, saving model to checkpoints/checkpoint_lr_0.09102464833032031_units_layer01_64_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.08270\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.08270\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.08270\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.08270\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.08270\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.08270\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.08270\n",
      "\n",
      "Epoch 27: val_mse did not improve from 0.08270\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.08270\n",
      "\n",
      "Epoch 29: val_mse did not improve from 0.08270\n",
      "\n",
      "Epoch 30: val_mse did not improve from 0.08270\n",
      "\n",
      "Epoch 31: val_mse did not improve from 0.08270\n",
      "\n",
      "Epoch 32: val_mse did not improve from 0.08270\n",
      "\n",
      "Epoch 33: val_mse did not improve from 0.08270\n",
      "\n",
      "Epoch 34: val_mse did not improve from 0.08270\n",
      "num acquisition: 11, time elapsed: 1932.91s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.01748, saving model to checkpoints/checkpoint_lr_0.02369394098644206_units_layer01_64_units_layer02_32_l2_0.00857761063338975_batch_128.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.01748\n",
      "\n",
      "Epoch 3: val_mse improved from 0.01748 to 0.01596, saving model to checkpoints/checkpoint_lr_0.02369394098644206_units_layer01_64_units_layer02_32_l2_0.00857761063338975_batch_128.keras\n",
      "\n",
      "Epoch 4: val_mse improved from 0.01596 to 0.01590, saving model to checkpoints/checkpoint_lr_0.02369394098644206_units_layer01_64_units_layer02_32_l2_0.00857761063338975_batch_128.keras\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.01590\n",
      "\n",
      "Epoch 6: val_mse improved from 0.01590 to 0.01508, saving model to checkpoints/checkpoint_lr_0.02369394098644206_units_layer01_64_units_layer02_32_l2_0.00857761063338975_batch_128.keras\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.01508\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.01508\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.01508\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.01508\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.01508\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.01508\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.01508\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.01508\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.01508\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.01508\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.01508\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.01508\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.01508\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.01508\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.01508\n",
      "num acquisition: 12, time elapsed: 1947.61s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.01544, saving model to checkpoints/checkpoint_lr_0.008739149488109178_units_layer01_128_units_layer02_128_l2_0.007974888470750221_batch_64.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.01544\n",
      "\n",
      "Epoch 3: val_mse improved from 0.01544 to 0.01497, saving model to checkpoints/checkpoint_lr_0.008739149488109178_units_layer01_128_units_layer02_128_l2_0.007974888470750221_batch_64.keras\n",
      "\n",
      "Epoch 4: val_mse improved from 0.01497 to 0.01228, saving model to checkpoints/checkpoint_lr_0.008739149488109178_units_layer01_128_units_layer02_128_l2_0.007974888470750221_batch_64.keras\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.01228\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.01228\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.01228\n",
      "\n",
      "Epoch 8: val_mse improved from 0.01228 to 0.01182, saving model to checkpoints/checkpoint_lr_0.008739149488109178_units_layer01_128_units_layer02_128_l2_0.007974888470750221_batch_64.keras\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.01182\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.01182\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.01182\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.01182\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.01182\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.01182\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.01182\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.01182\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.01182\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.01182\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.01182\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.01182\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.01182\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.01182\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.01182\n",
      "num acquisition: 13, time elapsed: 1984.05s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.01388, saving model to checkpoints/checkpoint_lr_0.017397607208191716_units_layer01_16_units_layer02_16_l2_0.0005169597501302832_batch_64.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.01388 to 0.01214, saving model to checkpoints/checkpoint_lr_0.017397607208191716_units_layer01_16_units_layer02_16_l2_0.0005169597501302832_batch_64.keras\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.01214\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.01214\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.01214\n",
      "\n",
      "Epoch 6: val_mse improved from 0.01214 to 0.01198, saving model to checkpoints/checkpoint_lr_0.017397607208191716_units_layer01_16_units_layer02_16_l2_0.0005169597501302832_batch_64.keras\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.01198\n",
      "\n",
      "Epoch 8: val_mse improved from 0.01198 to 0.01047, saving model to checkpoints/checkpoint_lr_0.017397607208191716_units_layer01_16_units_layer02_16_l2_0.0005169597501302832_batch_64.keras\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.01047\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.01047\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.01047\n",
      "\n",
      "Epoch 12: val_mse improved from 0.01047 to 0.01019, saving model to checkpoints/checkpoint_lr_0.017397607208191716_units_layer01_16_units_layer02_16_l2_0.0005169597501302832_batch_64.keras\n",
      "\n",
      "Epoch 13: val_mse improved from 0.01019 to 0.00960, saving model to checkpoints/checkpoint_lr_0.017397607208191716_units_layer01_16_units_layer02_16_l2_0.0005169597501302832_batch_64.keras\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.00960\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.00960\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.00960\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.00960\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.00960\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.00960\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.00960\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.00960\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.00960\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.00960\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.00960\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.00960\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.00960\n",
      "\n",
      "Epoch 27: val_mse did not improve from 0.00960\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.00960\n",
      "num acquisition: 14, time elapsed: 2012.13s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.03620, saving model to checkpoints/checkpoint_lr_0.08837511689615422_units_layer01_16_units_layer02_128_l2_0.006755748099089401_batch_128.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.03620 to 0.03439, saving model to checkpoints/checkpoint_lr_0.08837511689615422_units_layer01_16_units_layer02_128_l2_0.006755748099089401_batch_128.keras\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.03439\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.03439\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.03439\n",
      "\n",
      "Epoch 6: val_mse improved from 0.03439 to 0.03394, saving model to checkpoints/checkpoint_lr_0.08837511689615422_units_layer01_16_units_layer02_128_l2_0.006755748099089401_batch_128.keras\n",
      "\n",
      "Epoch 7: val_mse improved from 0.03394 to 0.02843, saving model to checkpoints/checkpoint_lr_0.08837511689615422_units_layer01_16_units_layer02_128_l2_0.006755748099089401_batch_128.keras\n",
      "\n",
      "Epoch 8: val_mse improved from 0.02843 to 0.02761, saving model to checkpoints/checkpoint_lr_0.08837511689615422_units_layer01_16_units_layer02_128_l2_0.006755748099089401_batch_128.keras\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.02761\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.02761\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.02761\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.02761\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.02761\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.02761\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.02761\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.02761\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.02761\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.02761\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.02761\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.02761\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.02761\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.02761\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.02761\n",
      "num acquisition: 15, time elapsed: 2026.12s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.09034, saving model to checkpoints/checkpoint_lr_0.0910908382425424_units_layer01_256_units_layer02_32_l2_0.005761709614674088_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.09034\n",
      "\n",
      "Epoch 3: val_mse improved from 0.09034 to 0.09016, saving model to checkpoints/checkpoint_lr_0.0910908382425424_units_layer01_256_units_layer02_32_l2_0.005761709614674088_batch_16.keras\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 12: val_mse improved from 0.09016 to 0.09008, saving model to checkpoints/checkpoint_lr_0.0910908382425424_units_layer01_256_units_layer02_32_l2_0.005761709614674088_batch_16.keras\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.09008\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.09008\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.09008\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.09008\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.09008\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.09008\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.09008\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.09008\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.09008\n",
      "\n",
      "Epoch 22: val_mse improved from 0.09008 to 0.09005, saving model to checkpoints/checkpoint_lr_0.0910908382425424_units_layer01_256_units_layer02_32_l2_0.005761709614674088_batch_16.keras\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.09005\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.09005\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.09005\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.09005\n",
      "\n",
      "Epoch 27: val_mse did not improve from 0.09005\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.09005\n",
      "\n",
      "Epoch 29: val_mse did not improve from 0.09005\n",
      "\n",
      "Epoch 30: val_mse did not improve from 0.09005\n",
      "\n",
      "Epoch 31: val_mse did not improve from 0.09005\n",
      "\n",
      "Epoch 32: val_mse did not improve from 0.09005\n",
      "\n",
      "Epoch 33: val_mse did not improve from 0.09005\n",
      "\n",
      "Epoch 34: val_mse did not improve from 0.09005\n",
      "\n",
      "Epoch 35: val_mse did not improve from 0.09005\n",
      "\n",
      "Epoch 36: val_mse did not improve from 0.09005\n",
      "\n",
      "Epoch 37: val_mse did not improve from 0.09005\n",
      "num acquisition: 16, time elapsed: 2344.69s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.07449, saving model to checkpoints/checkpoint_lr_0.0526670383464035_units_layer01_256_units_layer02_32_l2_0.008520865017024325_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.07449 to 0.06543, saving model to checkpoints/checkpoint_lr_0.0526670383464035_units_layer01_256_units_layer02_32_l2_0.008520865017024325_batch_16.keras\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.06543\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.06543\n",
      "\n",
      "Epoch 5: val_mse improved from 0.06543 to 0.06291, saving model to checkpoints/checkpoint_lr_0.0526670383464035_units_layer01_256_units_layer02_32_l2_0.008520865017024325_batch_16.keras\n",
      "\n",
      "Epoch 6: val_mse improved from 0.06291 to 0.06155, saving model to checkpoints/checkpoint_lr_0.0526670383464035_units_layer01_256_units_layer02_32_l2_0.008520865017024325_batch_16.keras\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.06155\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.06155\n",
      "\n",
      "Epoch 9: val_mse improved from 0.06155 to 0.06100, saving model to checkpoints/checkpoint_lr_0.0526670383464035_units_layer01_256_units_layer02_32_l2_0.008520865017024325_batch_16.keras\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.06100\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.06100\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.06100\n",
      "\n",
      "Epoch 13: val_mse improved from 0.06100 to 0.05955, saving model to checkpoints/checkpoint_lr_0.0526670383464035_units_layer01_256_units_layer02_32_l2_0.008520865017024325_batch_16.keras\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.05955\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.05955\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.05955\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.05955\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.05955\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.05955\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.05955\n",
      "\n",
      "Epoch 21: val_mse improved from 0.05955 to 0.05774, saving model to checkpoints/checkpoint_lr_0.0526670383464035_units_layer01_256_units_layer02_32_l2_0.008520865017024325_batch_16.keras\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.05774\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.05774\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.05774\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.05774\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.05774\n",
      "\n",
      "Epoch 27: val_mse did not improve from 0.05774\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.05774\n",
      "\n",
      "Epoch 29: val_mse did not improve from 0.05774\n",
      "\n",
      "Epoch 30: val_mse did not improve from 0.05774\n",
      "\n",
      "Epoch 31: val_mse did not improve from 0.05774\n",
      "\n",
      "Epoch 32: val_mse did not improve from 0.05774\n",
      "\n",
      "Epoch 33: val_mse did not improve from 0.05774\n",
      "\n",
      "Epoch 34: val_mse did not improve from 0.05774\n",
      "\n",
      "Epoch 35: val_mse did not improve from 0.05774\n",
      "\n",
      "Epoch 36: val_mse did not improve from 0.05774\n",
      "num acquisition: 17, time elapsed: 2671.33s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.09041, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_256_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.09041 to 0.09035, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_256_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 3: val_mse improved from 0.09035 to 0.09016, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_256_units_layer02_32_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.09016\n",
      "num acquisition: 18, time elapsed: 2831.07s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.03312, saving model to checkpoints/checkpoint_lr_0.0624478711196806_units_layer01_16_units_layer02_64_l2_0.002338427050175054_batch_128.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.03312 to 0.03048, saving model to checkpoints/checkpoint_lr_0.0624478711196806_units_layer01_16_units_layer02_64_l2_0.002338427050175054_batch_128.keras\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.03048\n",
      "\n",
      "Epoch 4: val_mse improved from 0.03048 to 0.02448, saving model to checkpoints/checkpoint_lr_0.0624478711196806_units_layer01_16_units_layer02_64_l2_0.002338427050175054_batch_128.keras\n",
      "\n",
      "Epoch 5: val_mse improved from 0.02448 to 0.02213, saving model to checkpoints/checkpoint_lr_0.0624478711196806_units_layer01_16_units_layer02_64_l2_0.002338427050175054_batch_128.keras\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.02213\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.02213\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.02213\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.02213\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.02213\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.02213\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.02213\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.02213\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.02213\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.02213\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.02213\n",
      "\n",
      "Epoch 17: val_mse improved from 0.02213 to 0.02211, saving model to checkpoints/checkpoint_lr_0.0624478711196806_units_layer01_16_units_layer02_64_l2_0.002338427050175054_batch_128.keras\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.02211\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.02211\n",
      "\n",
      "Epoch 20: val_mse improved from 0.02211 to 0.01955, saving model to checkpoints/checkpoint_lr_0.0624478711196806_units_layer01_16_units_layer02_64_l2_0.002338427050175054_batch_128.keras\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.01955\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.01955\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.01955\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.01955\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.01955\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.01955\n",
      "\n",
      "Epoch 27: val_mse did not improve from 0.01955\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.01955\n",
      "\n",
      "Epoch 29: val_mse did not improve from 0.01955\n",
      "\n",
      "Epoch 30: val_mse did not improve from 0.01955\n",
      "\n",
      "Epoch 31: val_mse did not improve from 0.01955\n",
      "\n",
      "Epoch 32: val_mse did not improve from 0.01955\n",
      "\n",
      "Epoch 33: val_mse improved from 0.01955 to 0.01930, saving model to checkpoints/checkpoint_lr_0.0624478711196806_units_layer01_16_units_layer02_64_l2_0.002338427050175054_batch_128.keras\n",
      "\n",
      "Epoch 34: val_mse did not improve from 0.01930\n",
      "\n",
      "Epoch 35: val_mse did not improve from 0.01930\n",
      "\n",
      "Epoch 36: val_mse did not improve from 0.01930\n",
      "\n",
      "Epoch 37: val_mse did not improve from 0.01930\n",
      "\n",
      "Epoch 38: val_mse did not improve from 0.01930\n",
      "\n",
      "Epoch 39: val_mse did not improve from 0.01930\n",
      "\n",
      "Epoch 40: val_mse did not improve from 0.01930\n",
      "\n",
      "Epoch 41: val_mse did not improve from 0.01930\n",
      "\n",
      "Epoch 42: val_mse did not improve from 0.01930\n",
      "\n",
      "Epoch 43: val_mse did not improve from 0.01930\n",
      "\n",
      "Epoch 44: val_mse did not improve from 0.01930\n",
      "\n",
      "Epoch 45: val_mse did not improve from 0.01930\n",
      "\n",
      "Epoch 46: val_mse did not improve from 0.01930\n",
      "\n",
      "Epoch 47: val_mse did not improve from 0.01930\n",
      "\n",
      "Epoch 48: val_mse did not improve from 0.01930\n",
      "num acquisition: 19, time elapsed: 2859.45s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.09032, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_256_units_layer02_32_l2_0.01_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.09032 to 0.09016, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_256_units_layer02_32_l2_0.01_batch_16.keras\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.09016\n",
      "\n",
      "Epoch 5: val_mse improved from 0.09016 to 0.09003, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_256_units_layer02_32_l2_0.01_batch_16.keras\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.09003\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.09003\n",
      "num acquisition: 20, time elapsed: 3039.04s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.01908, saving model to checkpoints/checkpoint_lr_0.01998421277320372_units_layer01_16_units_layer02_64_l2_0.00324295166318598_batch_32.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.01908\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.01908\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.01908\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.01908\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.01908\n",
      "\n",
      "Epoch 7: val_mse improved from 0.01908 to 0.01842, saving model to checkpoints/checkpoint_lr_0.01998421277320372_units_layer01_16_units_layer02_64_l2_0.00324295166318598_batch_32.keras\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.01842\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.01842\n",
      "\n",
      "Epoch 10: val_mse improved from 0.01842 to 0.01708, saving model to checkpoints/checkpoint_lr_0.01998421277320372_units_layer01_16_units_layer02_64_l2_0.00324295166318598_batch_32.keras\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.01708\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.01708\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.01708\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.01708\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.01708\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.01708\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.01708\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.01708\n",
      "\n",
      "Epoch 19: val_mse improved from 0.01708 to 0.01699, saving model to checkpoints/checkpoint_lr_0.01998421277320372_units_layer01_16_units_layer02_64_l2_0.00324295166318598_batch_32.keras\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.01699\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.01699\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.01699\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.01699\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.01699\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.01699\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.01699\n",
      "\n",
      "Epoch 27: val_mse did not improve from 0.01699\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.01699\n",
      "\n",
      "Epoch 29: val_mse did not improve from 0.01699\n",
      "\n",
      "Epoch 30: val_mse did not improve from 0.01699\n",
      "\n",
      "Epoch 31: val_mse did not improve from 0.01699\n",
      "\n",
      "Epoch 32: val_mse did not improve from 0.01699\n",
      "\n",
      "Epoch 33: val_mse did not improve from 0.01699\n",
      "\n",
      "Epoch 34: val_mse did not improve from 0.01699\n",
      "num acquisition: 21, time elapsed: 3102.14s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.02015, saving model to checkpoints/checkpoint_lr_0.024008986708019885_units_layer01_128_units_layer02_128_l2_0.0028992355106169454_batch_128.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.02015 to 0.01364, saving model to checkpoints/checkpoint_lr_0.024008986708019885_units_layer01_128_units_layer02_128_l2_0.0028992355106169454_batch_128.keras\n",
      "\n",
      "Epoch 3: val_mse improved from 0.01364 to 0.01303, saving model to checkpoints/checkpoint_lr_0.024008986708019885_units_layer01_128_units_layer02_128_l2_0.0028992355106169454_batch_128.keras\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.01303\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.01303\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.01303\n",
      "\n",
      "Epoch 7: val_mse improved from 0.01303 to 0.01257, saving model to checkpoints/checkpoint_lr_0.024008986708019885_units_layer01_128_units_layer02_128_l2_0.0028992355106169454_batch_128.keras\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.01257\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.01257\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.01257\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.01257\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.01257\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.01257\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.01257\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.01257\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.01257\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.01257\n",
      "\n",
      "Epoch 18: val_mse improved from 0.01257 to 0.01257, saving model to checkpoints/checkpoint_lr_0.024008986708019885_units_layer01_128_units_layer02_128_l2_0.0028992355106169454_batch_128.keras\n",
      "\n",
      "Epoch 19: val_mse improved from 0.01257 to 0.01188, saving model to checkpoints/checkpoint_lr_0.024008986708019885_units_layer01_128_units_layer02_128_l2_0.0028992355106169454_batch_128.keras\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.01188\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.01188\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.01188\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.01188\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.01188\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.01188\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.01188\n",
      "\n",
      "Epoch 27: val_mse did not improve from 0.01188\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.01188\n",
      "\n",
      "Epoch 29: val_mse improved from 0.01188 to 0.01168, saving model to checkpoints/checkpoint_lr_0.024008986708019885_units_layer01_128_units_layer02_128_l2_0.0028992355106169454_batch_128.keras\n",
      "\n",
      "Epoch 30: val_mse did not improve from 0.01168\n",
      "\n",
      "Epoch 31: val_mse did not improve from 0.01168\n",
      "\n",
      "Epoch 32: val_mse did not improve from 0.01168\n",
      "\n",
      "Epoch 33: val_mse did not improve from 0.01168\n",
      "\n",
      "Epoch 34: val_mse did not improve from 0.01168\n",
      "\n",
      "Epoch 35: val_mse did not improve from 0.01168\n",
      "\n",
      "Epoch 36: val_mse did not improve from 0.01168\n",
      "\n",
      "Epoch 37: val_mse did not improve from 0.01168\n",
      "\n",
      "Epoch 38: val_mse did not improve from 0.01168\n",
      "\n",
      "Epoch 39: val_mse did not improve from 0.01168\n",
      "\n",
      "Epoch 40: val_mse did not improve from 0.01168\n",
      "\n",
      "Epoch 41: val_mse did not improve from 0.01168\n",
      "\n",
      "Epoch 42: val_mse did not improve from 0.01168\n",
      "\n",
      "Epoch 43: val_mse did not improve from 0.01168\n",
      "\n",
      "Epoch 44: val_mse did not improve from 0.01168\n",
      "num acquisition: 22, time elapsed: 3145.32s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.04438, saving model to checkpoints/checkpoint_lr_0.04690319794305827_units_layer01_16_units_layer02_128_l2_0.009153626026500588_batch_32.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.04438 to 0.03958, saving model to checkpoints/checkpoint_lr_0.04690319794305827_units_layer01_16_units_layer02_128_l2_0.009153626026500588_batch_32.keras\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.03958\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.03958\n",
      "\n",
      "Epoch 5: val_mse improved from 0.03958 to 0.03610, saving model to checkpoints/checkpoint_lr_0.04690319794305827_units_layer01_16_units_layer02_128_l2_0.009153626026500588_batch_32.keras\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.03610\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.03610\n",
      "\n",
      "Epoch 8: val_mse improved from 0.03610 to 0.03270, saving model to checkpoints/checkpoint_lr_0.04690319794305827_units_layer01_16_units_layer02_128_l2_0.009153626026500588_batch_32.keras\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.03270\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.03270\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.03270\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.03270\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.03270\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.03270\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.03270\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.03270\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.03270\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.03270\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.03270\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.03270\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.03270\n",
      "\n",
      "Epoch 22: val_mse improved from 0.03270 to 0.03217, saving model to checkpoints/checkpoint_lr_0.04690319794305827_units_layer01_16_units_layer02_128_l2_0.009153626026500588_batch_32.keras\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.03217\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.03217\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.03217\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.03217\n",
      "\n",
      "Epoch 27: val_mse did not improve from 0.03217\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.03217\n",
      "\n",
      "Epoch 29: val_mse did not improve from 0.03217\n",
      "\n",
      "Epoch 30: val_mse did not improve from 0.03217\n",
      "\n",
      "Epoch 31: val_mse did not improve from 0.03217\n",
      "\n",
      "Epoch 32: val_mse did not improve from 0.03217\n",
      "\n",
      "Epoch 33: val_mse did not improve from 0.03217\n",
      "\n",
      "Epoch 34: val_mse did not improve from 0.03217\n",
      "\n",
      "Epoch 35: val_mse did not improve from 0.03217\n",
      "\n",
      "Epoch 36: val_mse did not improve from 0.03217\n",
      "\n",
      "Epoch 37: val_mse did not improve from 0.03217\n",
      "num acquisition: 23, time elapsed: 3214.59s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.08586, saving model to checkpoints/checkpoint_lr_0.08654748219027049_units_layer01_32_units_layer02_16_l2_0.006943380188624562_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.08586 to 0.07944, saving model to checkpoints/checkpoint_lr_0.08654748219027049_units_layer01_32_units_layer02_16_l2_0.006943380188624562_batch_16.keras\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.07944\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.07944\n",
      "\n",
      "Epoch 5: val_mse improved from 0.07944 to 0.07760, saving model to checkpoints/checkpoint_lr_0.08654748219027049_units_layer01_32_units_layer02_16_l2_0.006943380188624562_batch_16.keras\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.07760\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.07760\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.07760\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.07760\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.07760\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.07760\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.07760\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.07760\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.07760\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.07760\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.07760\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.07760\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.07760\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.07760\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.07760\n",
      "num acquisition: 24, time elapsed: 3287.46s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.02880, saving model to checkpoints/checkpoint_lr_0.04565156303490167_units_layer01_32_units_layer02_16_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.02880\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.02880\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.02880\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.02880\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.02880\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.02880\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.02880\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.02880\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.02880\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.02880\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.02880\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.02880\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.02880\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.02880\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.02880\n",
      "num acquisition: 25, time elapsed: 3346.21s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.09054, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_32_units_layer02_16_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.09054 to 0.09015, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_32_units_layer02_16_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.09015\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.09015\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.09015\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.09015\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.09015\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.09015\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.09015\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.09015\n",
      "\n",
      "Epoch 11: val_mse improved from 0.09015 to 0.09009, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_32_units_layer02_16_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.09009\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.09009\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.09009\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.09009\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.09009\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.09009\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.09009\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.09009\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.09009\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.09009\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.09009\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.09009\n",
      "\n",
      "Epoch 24: val_mse improved from 0.09009 to 0.09008, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_32_units_layer02_16_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.09008\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.09008\n",
      "\n",
      "Epoch 27: val_mse did not improve from 0.09008\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.09008\n",
      "\n",
      "Epoch 29: val_mse did not improve from 0.09008\n",
      "\n",
      "Epoch 30: val_mse improved from 0.09008 to 0.09004, saving model to checkpoints/checkpoint_lr_0.1_units_layer01_32_units_layer02_16_l2_1e-06_batch_16.keras\n",
      "\n",
      "Epoch 31: val_mse did not improve from 0.09004\n",
      "\n",
      "Epoch 32: val_mse did not improve from 0.09004\n",
      "\n",
      "Epoch 33: val_mse did not improve from 0.09004\n",
      "\n",
      "Epoch 34: val_mse did not improve from 0.09004\n",
      "\n",
      "Epoch 35: val_mse did not improve from 0.09004\n",
      "\n",
      "Epoch 36: val_mse did not improve from 0.09004\n",
      "\n",
      "Epoch 37: val_mse did not improve from 0.09004\n",
      "\n",
      "Epoch 38: val_mse did not improve from 0.09004\n",
      "\n",
      "Epoch 39: val_mse did not improve from 0.09004\n",
      "\n",
      "Epoch 40: val_mse did not improve from 0.09004\n",
      "\n",
      "Epoch 41: val_mse did not improve from 0.09004\n",
      "\n",
      "Epoch 42: val_mse did not improve from 0.09004\n",
      "\n",
      "Epoch 43: val_mse did not improve from 0.09004\n",
      "\n",
      "Epoch 44: val_mse did not improve from 0.09004\n",
      "\n",
      "Epoch 45: val_mse did not improve from 0.09004\n",
      "num acquisition: 26, time elapsed: 3508.73s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.02309, saving model to checkpoints/checkpoint_lr_0.005941451462404463_units_layer01_32_units_layer02_32_l2_0.005494210324377404_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.02309 to 0.01469, saving model to checkpoints/checkpoint_lr_0.005941451462404463_units_layer01_32_units_layer02_32_l2_0.005494210324377404_batch_16.keras\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.01469\n",
      "\n",
      "Epoch 4: val_mse improved from 0.01469 to 0.01290, saving model to checkpoints/checkpoint_lr_0.005941451462404463_units_layer01_32_units_layer02_32_l2_0.005494210324377404_batch_16.keras\n",
      "\n",
      "Epoch 5: val_mse improved from 0.01290 to 0.01265, saving model to checkpoints/checkpoint_lr_0.005941451462404463_units_layer01_32_units_layer02_32_l2_0.005494210324377404_batch_16.keras\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.01265\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.01265\n",
      "\n",
      "Epoch 8: val_mse improved from 0.01265 to 0.01196, saving model to checkpoints/checkpoint_lr_0.005941451462404463_units_layer01_32_units_layer02_32_l2_0.005494210324377404_batch_16.keras\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.01196\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.01196\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.01196\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.01196\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.01196\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.01196\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.01196\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.01196\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.01196\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.01196\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.01196\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.01196\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.01196\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.01196\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.01196\n",
      "num acquisition: 27, time elapsed: 3592.29s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.01924, saving model to checkpoints/checkpoint_lr_0.04343007656085674_units_layer01_64_units_layer02_16_l2_0.0073417548566362106_batch_128.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.01924\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.01924\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.01924\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.01924\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.01924\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.01924\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.01924\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.01924\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.01924\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.01924\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.01924\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.01924\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.01924\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.01924\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.01924\n",
      "num acquisition: 28, time elapsed: 3605.35s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.02956, saving model to checkpoints/checkpoint_lr_0.06146215586199765_units_layer01_16_units_layer02_32_l2_0.006269642486633957_batch_64.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.02956\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.02956\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.02956\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.02956\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.02956\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.02956\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.02956\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.02956\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.02956\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.02956\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.02956\n",
      "\n",
      "Epoch 13: val_mse improved from 0.02956 to 0.02767, saving model to checkpoints/checkpoint_lr_0.06146215586199765_units_layer01_16_units_layer02_32_l2_0.006269642486633957_batch_64.keras\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.02767\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.02767\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.02767\n",
      "\n",
      "Epoch 17: val_mse did not improve from 0.02767\n",
      "\n",
      "Epoch 18: val_mse did not improve from 0.02767\n",
      "\n",
      "Epoch 19: val_mse did not improve from 0.02767\n",
      "\n",
      "Epoch 20: val_mse did not improve from 0.02767\n",
      "\n",
      "Epoch 21: val_mse did not improve from 0.02767\n",
      "\n",
      "Epoch 22: val_mse did not improve from 0.02767\n",
      "\n",
      "Epoch 23: val_mse did not improve from 0.02767\n",
      "\n",
      "Epoch 24: val_mse did not improve from 0.02767\n",
      "\n",
      "Epoch 25: val_mse did not improve from 0.02767\n",
      "\n",
      "Epoch 26: val_mse did not improve from 0.02767\n",
      "\n",
      "Epoch 27: val_mse did not improve from 0.02767\n",
      "\n",
      "Epoch 28: val_mse did not improve from 0.02767\n",
      "num acquisition: 29, time elapsed: 3635.29s\n",
      "\n",
      "Epoch 1: val_mse improved from inf to 0.09010, saving model to checkpoints/checkpoint_lr_0.08899131110190651_units_layer01_128_units_layer02_64_l2_0.009508348935691475_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 3: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 4: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 5: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 6: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 7: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 8: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 9: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 10: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 11: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 12: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 13: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 14: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 15: val_mse did not improve from 0.09010\n",
      "\n",
      "Epoch 16: val_mse did not improve from 0.09010\n",
      "num acquisition: 30, time elapsed: 3735.72s\n"
     ]
    }
   ],
   "source": [
    "# Define the bounds of the hyperparameters\n",
    "bounds = [\n",
    "    {'name': 'learning_rate', 'type': 'continuous', 'domain': (1e-5, 1e-1)},\n",
    "    {'name': 'units_layer01', 'type': 'discrete', 'domain': (16, 32, 64, 128, 256)},\n",
    "    {'name': 'units_layer02', 'type': 'discrete', 'domain': (16, 32, 64, 128, 256)},\n",
    "    {'name': 'l2_reg', 'type': 'continuous', 'domain': (1e-6, 1e-2)},\n",
    "    {'name': 'batch_size', 'type': 'discrete', 'domain': (16, 32, 64, 128)}\n",
    "]\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "optimizer = GPyOpt.methods.BayesianOptimization(f=model_score, \n",
    "                                                domain=bounds, \n",
    "                                                acquisition_type='EI'  # Expected Improvement\n",
    ")\n",
    "#optimizer.run_optimization(max_iter=30, verbosity=True, eps=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_mse improved from inf to 0.04451, saving model to checkpoints/checkpoint_lr_0.038835490520284635_units_layer01_128_units_layer02_64_l2_0.004401478381980411_batch_16.keras\n",
      "\n",
      "Epoch 2: val_mse improved from 0.04451 to 0.03535, saving model to checkpoints/checkpoint_lr_0.038835490520284635_units_layer01_128_units_layer02_64_l2_0.004401478381980411_batch_16.keras\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\GPyOpt\\core\\bo.py:151\u001b[0m, in \u001b[0;36mBO.run_optimization\u001b[1;34m(self, max_iter, max_time, eps, context, verbosity, save_models_parameters, report_file, evaluations_file, models_file)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggested_sample))\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# --- Evaluate *f* in X, augment Y and update cost function (if needed)\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# --- Update current evaluation time and function evaluations\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcum_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_zero\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\GPyOpt\\core\\bo.py:197\u001b[0m, in \u001b[0;36mBO.evaluate_objective\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_objective\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    194\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m    Evaluates the objective\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_new, cost_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggested_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcost\u001b[38;5;241m.\u001b[39mupdate_cost_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggested_sample, cost_new)\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_new))\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\GPyOpt\\core\\task\\objective.py:50\u001b[0m, in \u001b[0;36mSingleObjective.evaluate\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03mPerforms the evaluation of the objective at x.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_procs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 50\u001b[0m     f_evals, cost_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\GPyOpt\\core\\task\\objective.py:74\u001b[0m, in \u001b[0;36mSingleObjective._eval_func\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     73\u001b[0m     st_time    \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 74\u001b[0m     rlt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     f_evals     \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([f_evals,rlt])\n\u001b[0;32m     76\u001b[0m     cost_evals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mst_time]\n",
      "Cell \u001b[1;32mIn[20], line 20\u001b[0m, in \u001b[0;36mmodel_score\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     12\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     13\u001b[0m     EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mse\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     14\u001b[0m     ModelCheckpoint(checkpoint_path, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mse\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     15\u001b[0m ]\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate),\n\u001b[0;32m     17\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     18\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m val_mse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mval_mse\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer.run_optimization(max_iter=30, verbosity=True, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (36,) and (35, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(opt_res_param))\n\u001b[0;32m      3\u001b[0m opt_res_score \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mY\n\u001b[1;32m----> 4\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_res_param\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_res_score\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\matplotlib\\pyplot.py:3794\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3786\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3788\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3798\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3800\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1779\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1779\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\matplotlib\\axes\\_base.py:296\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    295\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thmru\\anaconda3\\envs\\BayesianOptimization\\Lib\\site-packages\\matplotlib\\axes\\_base.py:486\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    483\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    490\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (36,) and (35, 1)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "opt_res_param = optimizer.X\n",
    "print(len(opt_res_param))\n",
    "opt_res_score = optimizer.Y\n",
    "plt.plot(opt_res_param[:, 3], opt_res_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = \"checkpoints\"\n",
    "\n",
    "# Get all file names in the folder\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "# Print the file names\n",
    "file_names_vec = []\n",
    "for file_name in file_names:\n",
    "    file_names_vec.append(file_name)\n",
    "\n",
    "def get_BO_values(filenames):\n",
    "    \n",
    "    for(filename in file_names):\n",
    "        # Input string\n",
    "        input_string = filename\n",
    "\n",
    "        # Regular expression to extract key-value pairs\n",
    "        pattern = r\"(\\w+)_([\\d\\.]+)\"  # Matches \"key_value\" pairs\n",
    "        matches = re.findall(pattern, input_string)\n",
    "\n",
    "        # Convert to dictionary\n",
    "        parameters = {key: float(value) if '.' in value else int(value) for key, value in matches}\n",
    "\n",
    "        # Access specific parameters\n",
    "        lr = round(parameters.get(\"lr\", 0), 3)\n",
    "        units = parameters.get(\"units\", 0)\n",
    "        l2 = round(parameters.get(\"l2\", 0), 3)\n",
    "        batch = parameters.get(\"batch\", 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint_lr_0.00517534614537441_units_128_l2_0.000957983117723653_batch_64.keras'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names_vec[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BayesianOptimization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
